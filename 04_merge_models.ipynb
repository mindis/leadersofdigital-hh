{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmvMP7rF8toU"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZQjUfMxNnxh"
   },
   "outputs": [],
   "source": [
    "!pip install pymorphy2 sparse_dot_topn swifter\n",
    "!python -m nltk.downloader stopwords\n",
    "!python -m nltk.downloader wordnet\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLRafaC0LC_8"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bVC0QR09LGOI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import json\n",
    "import gzip\n",
    "import codecs\n",
    "\n",
    "from itertools import islice, chain, filterfalse\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import scipy.stats as ss\n",
    "import pandas as pd\n",
    "\n",
    "import lxml.html as lhtml\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkkEzd9lLG20"
   },
   "outputs": [],
   "source": [
    "WORKDIR = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dF37F2YVzsh1"
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"{WORKDIR}/data\" \"{WORKDIR}/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pANZ8vyrwCgh"
   },
   "outputs": [],
   "source": [
    "def save_array(a, filename: str, sparse: bool = False, **params):\n",
    "    if sparse and not sp.issparse(a):\n",
    "        a = sp.csr_matrix(a)\n",
    "    elif not sparse and sp.issparse(a):\n",
    "        a = np.asarray(a.todense())\n",
    "\n",
    "    with open(filename, 'wb') as f_data:\n",
    "        save = sp.save_npz if sparse else np.save\n",
    "        return save(f_data, a, **params)\n",
    "\n",
    "\n",
    "def load_array(filename: str, sparse: bool = False, **params):\n",
    "    with open(filename, 'rb') as f_data:\n",
    "        load = sp.load_npz if sparse else np.load\n",
    "        return load(f_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_74JYgdUYYw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poisk/.conda/envs/ml-py37/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specializations</th>\n",
       "      <th>is_train</th>\n",
       "      <th>area_id</th>\n",
       "      <th>compensation_from</th>\n",
       "      <th>compensation_to</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>currency</th>\n",
       "      <th>employer</th>\n",
       "      <th>employment</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>work_schedule</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacancy_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>RUR</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9aa259f8724</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[211]</td>\n",
       "      <td>True</td>\n",
       "      <td>1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11ecc72a7a76</td>\n",
       "      <td>project</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[389, 412, 437]</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>RUR</td>\n",
       "      <td>e1e424ceb5e4</td>\n",
       "      <td>full</td>\n",
       "      <td>noExperience</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1002</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>BYR</td>\n",
       "      <td>943fd4a3770a</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           specializations  is_train  area_id  \\\n",
       "vacancy_id                                                      \n",
       "1           [242, 256, 302, 324, 358, 440]      True       26   \n",
       "2                                      NaN     False      160   \n",
       "3                                    [211]      True     1002   \n",
       "4                          [389, 412, 437]      True       22   \n",
       "5                                      NaN     False     1002   \n",
       "\n",
       "            compensation_from  compensation_to creation_date currency  \\\n",
       "vacancy_id                                                              \n",
       "1                     22000.0          24000.0    2019-01-24      RUR   \n",
       "2                         NaN              NaN    2019-07-26      NaN   \n",
       "3                         NaN              NaN    2019-04-15      NaN   \n",
       "4                         NaN          36000.0    2019-07-12      RUR   \n",
       "5                       600.0              NaN    2019-01-17      BYR   \n",
       "\n",
       "                employer employment work_experience work_schedule  \n",
       "vacancy_id                                                         \n",
       "1           0ce23382345c       full    between1And3       fullDay  \n",
       "2           b9aa259f8724       full    between1And3       fullDay  \n",
       "3           11ecc72a7a76    project    between1And3       fullDay  \n",
       "4           e1e424ceb5e4       full    noExperience       fullDay  \n",
       "5           943fd4a3770a       full    between1And3       fullDay  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_specializations(s):\n",
    "    res = s[1:-1].split(',')\n",
    "    res = map(int, res)\n",
    "    res = list(res)\n",
    "    # res = np.asarray(res, dtype=int)\n",
    "    return res\n",
    "\n",
    "vacancies_file = os.path.join(WORKDIR, 'data/vacancies_info.csv.gz')\n",
    "\n",
    "if not os.path.isfile(vacancies_file):\n",
    "    # Загружаем специализации для обучения\n",
    "    df_train_ids = pd.read_csv(\n",
    "        os.path.join(WORKDIR, 'train_labels.csv.gz'),\n",
    "        index_col='vacancy_id',\n",
    "        compression='gzip',\n",
    "    )\n",
    "\n",
    "    df_train_ids['specializations'] = df_train_ids['specializations'].map(parse_specializations)\n",
    "    df_train_ids['is_train'] = True\n",
    "\n",
    "    # Загружаем специализации для теста\n",
    "    df_test_ids = pd.read_csv(\n",
    "        os.path.join(WORKDIR, 'test_vacancy_ids.csv.gz'),\n",
    "        index_col='vacancy_id',\n",
    "        compression='gzip',\n",
    "    )\n",
    "\n",
    "    # Объединяем в один датафрейм\n",
    "    df_all_ids = pd.concat([df_train_ids, df_test_ids], axis=0)\n",
    "    df_all_ids['is_train'].fillna(False, inplace=True)\n",
    "    df_all_ids.sort_index(inplace=True)\n",
    "\n",
    "    # Загружаем информацию о каждой из вакансий\n",
    "    df_vacancies_info = pd.read_csv(\n",
    "        os.path.join(WORKDIR, 'vacancies_info.csv.gz'),\n",
    "        index_col='vacancy_id',\n",
    "        compression='gzip',\n",
    "    )\n",
    "\n",
    "    # Объединяем в один датафрейм\n",
    "    df_all_ids = pd.merge(df_all_ids, df_vacancies_info, left_index=True, right_index=True, how='left')\n",
    "\n",
    "    df_all_ids.to_csv(vacancies_file, index=True, compression='gzip')\n",
    "else:\n",
    "    df_all_ids = pd.read_csv(\n",
    "        vacancies_file,\n",
    "        index_col='vacancy_id',\n",
    "        compression='gzip',\n",
    "    )\n",
    "    df_all_ids.loc[df_all_ids['is_train'], 'specializations'] = \\\n",
    "        df_all_ids.loc[df_all_ids['is_train'], 'specializations'].map(parse_specializations)\n",
    "\n",
    "df_all_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lYTVqw_pCgrk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specializations</th>\n",
       "      <th>is_train</th>\n",
       "      <th>area_id</th>\n",
       "      <th>compensation_from</th>\n",
       "      <th>compensation_to</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>currency</th>\n",
       "      <th>employer</th>\n",
       "      <th>employment</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>work_schedule</th>\n",
       "      <th>joined_work</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacancy_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>RUR</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9aa259f8724</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[211]</td>\n",
       "      <td>True</td>\n",
       "      <td>1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11ecc72a7a76</td>\n",
       "      <td>project</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>project_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[389, 412, 437]</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>RUR</td>\n",
       "      <td>e1e424ceb5e4</td>\n",
       "      <td>full</td>\n",
       "      <td>noExperience</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_noExperience_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1002</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>BYR</td>\n",
       "      <td>943fd4a3770a</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           specializations  is_train  area_id  \\\n",
       "vacancy_id                                                      \n",
       "1           [242, 256, 302, 324, 358, 440]      True       26   \n",
       "2                                      NaN     False      160   \n",
       "3                                    [211]      True     1002   \n",
       "4                          [389, 412, 437]      True       22   \n",
       "5                                      NaN     False     1002   \n",
       "\n",
       "            compensation_from  compensation_to creation_date currency  \\\n",
       "vacancy_id                                                              \n",
       "1                     22000.0          24000.0    2019-01-24      RUR   \n",
       "2                         NaN              NaN    2019-07-26      NaN   \n",
       "3                         NaN              NaN    2019-04-15      NaN   \n",
       "4                         NaN          36000.0    2019-07-12      RUR   \n",
       "5                       600.0              NaN    2019-01-17      BYR   \n",
       "\n",
       "                employer employment work_experience work_schedule  \\\n",
       "vacancy_id                                                          \n",
       "1           0ce23382345c       full    between1And3       fullDay   \n",
       "2           b9aa259f8724       full    between1And3       fullDay   \n",
       "3           11ecc72a7a76    project    between1And3       fullDay   \n",
       "4           e1e424ceb5e4       full    noExperience       fullDay   \n",
       "5           943fd4a3770a       full    between1And3       fullDay   \n",
       "\n",
       "                             joined_work  \n",
       "vacancy_id                                \n",
       "1              full_between1And3_fullDay  \n",
       "2              full_between1And3_fullDay  \n",
       "3           project_between1And3_fullDay  \n",
       "4              full_noExperience_fullDay  \n",
       "5              full_between1And3_fullDay  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ids['joined_work'] = (\n",
    "    df_all_ids['employment'] + '_' +\n",
    "    df_all_ids['work_experience'] + '_' +\n",
    "    df_all_ids['work_schedule']\n",
    ")\n",
    "\n",
    "df_all_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MRLpSLHOp6Gc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912650, 14)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_vacancy_info = pd.get_dummies(df_all_ids[['employment', 'work_experience', 'work_schedule']], sparse=True)\n",
    "\n",
    "# features_vacancy_info = pd.get_dummies(df_all_ids['joined_work'], sparse=True)\n",
    "features_vacancy_info = features_vacancy_info.sparse.to_coo().tocsr()\n",
    "features_vacancy_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOBjiCFP7YOG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employer_chosen = df_all_ids.groupby(by='employer')['employer'].count().sort_values(ascending=False)\n",
    "employer_chosen = set(employer_chosen[employer_chosen >= 5].index)\n",
    "employer_chosen |= set(df_all_ids.loc[~df_all_ids['is_train'], 'employer'])\n",
    "\n",
    "len(employer_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cUzGioNj9u90"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specializations</th>\n",
       "      <th>is_train</th>\n",
       "      <th>area_id</th>\n",
       "      <th>compensation_from</th>\n",
       "      <th>compensation_to</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>currency</th>\n",
       "      <th>employer</th>\n",
       "      <th>employment</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>work_schedule</th>\n",
       "      <th>joined_work</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacancy_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>RUR</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9aa259f8724</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[211]</td>\n",
       "      <td>True</td>\n",
       "      <td>1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11ecc72a7a76</td>\n",
       "      <td>project</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>project_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[389, 412, 437]</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>RUR</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>full</td>\n",
       "      <td>noExperience</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_noExperience_fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1002</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>BYR</td>\n",
       "      <td>943fd4a3770a</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "      <td>full_between1And3_fullDay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           specializations  is_train  area_id  \\\n",
       "vacancy_id                                                      \n",
       "1           [242, 256, 302, 324, 358, 440]      True       26   \n",
       "2                                      NaN     False      160   \n",
       "3                                    [211]      True     1002   \n",
       "4                          [389, 412, 437]      True       22   \n",
       "5                                      NaN     False     1002   \n",
       "\n",
       "            compensation_from  compensation_to creation_date currency  \\\n",
       "vacancy_id                                                              \n",
       "1                     22000.0          24000.0    2019-01-24      RUR   \n",
       "2                         NaN              NaN    2019-07-26      NaN   \n",
       "3                         NaN              NaN    2019-04-15      NaN   \n",
       "4                         NaN          36000.0    2019-07-12      RUR   \n",
       "5                       600.0              NaN    2019-01-17      BYR   \n",
       "\n",
       "                employer employment work_experience work_schedule  \\\n",
       "vacancy_id                                                          \n",
       "1           0ce23382345c       full    between1And3       fullDay   \n",
       "2           b9aa259f8724       full    between1And3       fullDay   \n",
       "3           11ecc72a7a76    project    between1And3       fullDay   \n",
       "4                UNKNOWN       full    noExperience       fullDay   \n",
       "5           943fd4a3770a       full    between1And3       fullDay   \n",
       "\n",
       "                             joined_work  \n",
       "vacancy_id                                \n",
       "1              full_between1And3_fullDay  \n",
       "2              full_between1And3_fullDay  \n",
       "3           project_between1And3_fullDay  \n",
       "4              full_noExperience_fullDay  \n",
       "5              full_between1And3_fullDay  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_ids.loc[~df_all_ids['employer'].isin(employer_chosen), 'employer'] = 'UNKNOWN'\n",
    "df_all_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZoCj8bru-bxL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912650, 257995)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_employer = pd.get_dummies(df_all_ids['employer'], sparse=True)\n",
    "\n",
    "mapping_employer = features_employer.columns.tolist()\n",
    "mapping_employer = {e: i for i, e in enumerate(mapping_employer)}\n",
    "\n",
    "features_employer = features_employer.sparse.to_coo().tocsr()\n",
    "features_employer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Qb9mgU5w5Rm"
   },
   "outputs": [],
   "source": [
    "def make_onehot_csr_matrix(s: pd.Series):\n",
    "    mapping = defaultdict(lambda: len(mapping))\n",
    "\n",
    "    data = np.ones(shape=(s.shape[0], ))\n",
    "    indices = [mapping[k] for k in s]\n",
    "    indptr = np.arange(0, len(data) + 1)\n",
    "\n",
    "    X = sp.csr_matrix((data, indices, indptr), shape=(len(indptr) - 1, len(mapping)))\n",
    "    mapping.default_factory = None\n",
    "    mapping_inv = sorted(mapping, key=lambda e: mapping[e])\n",
    "\n",
    "    return mapping, mapping_inv, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m05rSmQaw7w1"
   },
   "outputs": [],
   "source": [
    "def make_onehot_multiple_csr_matrix(s: pd.Series):\n",
    "    mapping = defaultdict(lambda: len(mapping))\n",
    "\n",
    "    data, indices, indptr = [], [], [0, ]\n",
    "\n",
    "    for row in tqdm(s):\n",
    "        row = list(map(lambda e: mapping[e], row))\n",
    "\n",
    "        data.extend([1] * len(row))\n",
    "        indices.extend(row)\n",
    "        indptr.append(len(data))\n",
    "\n",
    "    X = sp.csr_matrix((data, indices, indptr), shape=(len(indptr) - 1, len(mapping)))\n",
    "    mapping.default_factory = None\n",
    "    mapping_inv = sorted(mapping, key=lambda e: mapping[e])\n",
    "\n",
    "    return mapping, mapping_inv, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8e2uGGdzxNM3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [00:02<00:00, 626953.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1456325, 620)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_spec, mapping_spec_inv, y_spec = \\\n",
    "    make_onehot_multiple_csr_matrix(df_all_ids.loc[df_all_ids['is_train'], 'specializations'])\n",
    "\n",
    "y_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYm7HjJkLU9L"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vacancies-01.json.gz',\n",
       " 'vacancies-02.json.gz',\n",
       " 'vacancies-03.json.gz',\n",
       " 'vacancies-04.json.gz',\n",
       " 'vacancies-05.json.gz',\n",
       " 'vacancies-06.json.gz',\n",
       " 'vacancies-07.json.gz',\n",
       " 'vacancies-08.json.gz',\n",
       " 'vacancies-09.json.gz',\n",
       " 'vacancies-10.json.gz']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancies_parts = (f for f in os.listdir(WORKDIR) if f.startswith('vacancies-'))\n",
    "vacancies_parts = sorted(vacancies_parts)\n",
    "vacancies_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cmv0omfcLbLy"
   },
   "outputs": [],
   "source": [
    "def read_vacancies_part(filename):\n",
    "    with gzip.open(filename, mode='r') as f_gz:\n",
    "        records = json.load(f_gz)\n",
    "        records = {int(k): v for k, v in records.items()}\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XJgRAIyLNh-6"
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "\n",
    "ru_morph = MorphAnalyzer()\n",
    "\n",
    "@lru_cache(maxsize=15000)\n",
    "def morph_process(token):\n",
    "    return ru_morph.parse(token)[0].normal_form\n",
    "\n",
    "@lru_cache(maxsize=5000)\n",
    "def preprocess_skill(s):\n",
    "    parts = re.sub('\\s+', ' ', s.strip().lower()).split()\n",
    "    parts = map(morph_process, parts)\n",
    "    return '_'.join(parts)\n",
    "\n",
    "stop_words = map(morph_process, stopwords.words('russian'))\n",
    "stop_words = stopwords.words('russian') + list(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzw4Qr2HOdrt"
   },
   "outputs": [],
   "source": [
    "def content_names_reader(vacancies_it, index):\n",
    "    for vacancy_id, vacancy_info in vacancies_it:\n",
    "        # name = re.sub('\\(.*?\\)', '', vacancy_info['name'].lower())\n",
    "        name = vacancy_info['name'].lower()\n",
    "        index.append(vacancy_id)\n",
    "        yield name\n",
    "\n",
    "def content_skills_reader(vacancies_it, index):\n",
    "    for vacancy_id, vacancy_info in vacancies_it:\n",
    "        skills = ' '.join(map(preprocess_skill, vacancy_info['key_skills']))\n",
    "        index.append(vacancy_id)\n",
    "        yield skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ltnZRdzoNlve"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def create_tfidf_vectorizer(mode, **params):\n",
    "    if mode == 'names':\n",
    "        vec = TfidfVectorizer(\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "            preprocessor=morph_process,\n",
    "            ngram_range=(1, 2),\n",
    "            min_df=5,\n",
    "            **params\n",
    "        )\n",
    "    elif mode == 'skills':\n",
    "        vec = TfidfVectorizer(\n",
    "            stop_words=stop_words,\n",
    "            token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "            min_df=5,\n",
    "            **params\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfdif_vectors(mode,\n",
    "                         content_array_file,\n",
    "                         content_terms_idfs,\n",
    "                         content_vacancies_mapping, ):\n",
    "    vacancies_it = map(lambda p: os.path.join(WORKDIR, p), tqdm(vacancies_parts))\n",
    "    vacancies_it = map(read_vacancies_part, vacancies_it)\n",
    "    vacancies_it = ((k, v) for p in vacancies_it for k, v in p.items())\n",
    "\n",
    "    index = []\n",
    "\n",
    "    if mode == 'names':\n",
    "        content = tqdm(content_names_reader(vacancies_it, index), position=0)\n",
    "    elif mode == 'skills':\n",
    "        content = tqdm(content_skills_reader(vacancies_it, index), position=0)\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "    vec = create_tfidf_vectorizer(mode)\n",
    "\n",
    "    # Считаем tfidf-вектора и сохраняем их\n",
    "    features = vec.fit_transform(content)\n",
    "    save_array(features, content_array_file, sparse=True)\n",
    "\n",
    "    # Сохраняем словарик с idf\n",
    "    vocabulary_inv = sorted(vec.vocabulary_, key=lambda e: vec.vocabulary_[e])\n",
    "    with open(content_terms_idfs, mode='w', encoding='utf8') as f_data:\n",
    "        for word, idf in zip(vocabulary_inv, vec.idf_):\n",
    "            print(word, \"%.16f\" % idf, sep='\\t', file=f_data)\n",
    "\n",
    "    # Сохраняем порядок вакансий в матрице\n",
    "    with open(content_vacancies_mapping, mode='w') as f_data:\n",
    "        print(*index, sep='\\n', file=f_data)\n",
    "\n",
    "    return vec, features, index\n",
    "\n",
    "\n",
    "def load_tfidf_vectors(mode,\n",
    "                       content_array_file,\n",
    "                       content_terms_idfs,\n",
    "                       content_vacancies_mapping, ):\n",
    "    # Грузим tfidf-вектора\n",
    "    features = load_array(content_array_file, sparse=True)\n",
    "\n",
    "    # Грузим TfIdfVectorizer\n",
    "    with open(content_terms_idfs, mode='r') as f_data:\n",
    "        f_data = map(lambda s: s.rstrip().split('\\t'), f_data)\n",
    "\n",
    "        vocabulary_inv, vocabulary_idf = [], []\n",
    "        for i, (word, idf) in enumerate(f_data):\n",
    "            vocabulary_inv.append(word)\n",
    "            vocabulary_idf.append(float(idf))\n",
    "\n",
    "    vec = create_tfidf_vectorizer(mode=mode, vocabulary=vocabulary_inv)\n",
    "    vec.idf_ = np.asarray(vocabulary_idf, dtype=float)\n",
    "\n",
    "    # Грузим порядок документов\n",
    "    with open(content_vacancies_mapping, mode='r') as f_data:\n",
    "        index = list(map(int, f_data))\n",
    "\n",
    "    return vec, features, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2_bvV52z0PE5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912650, 139435)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_names_array_file = os.path.join(WORKDIR, 'data/content_names_2.npz')\n",
    "content_names_terms_idfs = os.path.join(WORKDIR, 'data/content_names_2.idf')\n",
    "content_names_vacancies_mapping = os.path.join(WORKDIR, 'data/content_names_2.mapping')\n",
    "\n",
    "if not os.path.isfile(content_names_array_file):\n",
    "    index = []\n",
    "\n",
    "    vec, features_content_names, index = create_tfdif_vectors(\n",
    "        'names',\n",
    "        content_names_array_file,\n",
    "        content_names_terms_idfs,\n",
    "        content_names_vacancies_mapping,\n",
    "    )\n",
    "else:\n",
    "    vec, features_content_names, index = load_tfidf_vectors(\n",
    "        'names',\n",
    "        content_names_array_file,\n",
    "        content_names_terms_idfs,\n",
    "        content_names_vacancies_mapping,\n",
    "    )\n",
    "\n",
    "# Убеждаемся, что все правильно\n",
    "assert (np.asarray(index) == df_all_ids.index.values).all()\n",
    "assert features_content_names.shape == (df_all_ids.shape[0], len(vec.idf_))\n",
    "\n",
    "features_content_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2912650, 19402)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_skills_array_file = os.path.join(WORKDIR, 'data/content_skills_2.npz')\n",
    "content_skills_terms_idfs = os.path.join(WORKDIR, 'data/content_skills_2.idf')\n",
    "content_skills_vacancies_mapping = os.path.join(WORKDIR, 'data/content_skills_2.mapping')\n",
    "\n",
    "if not os.path.isfile(content_skills_array_file):\n",
    "    index = []\n",
    "\n",
    "    vec, features_content_skills, index = create_tfdif_vectors(\n",
    "        'skills',\n",
    "        content_skills_array_file,\n",
    "        content_skills_terms_idfs,\n",
    "        content_skills_vacancies_mapping,\n",
    "    )\n",
    "else:\n",
    "    vec, features_content_skills, index = load_tfidf_vectors(\n",
    "        'skills',\n",
    "        content_skills_array_file,\n",
    "        content_skills_terms_idfs,\n",
    "        content_skills_vacancies_mapping,\n",
    "    )\n",
    "\n",
    "# Убеждаемся, что все правильно\n",
    "assert (np.asarray(index) == df_all_ids.index.values).all()\n",
    "assert features_content_skills.shape == (df_all_ids.shape[0], len(vec.idf_))\n",
    "\n",
    "features_content_skills.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FRoThULolw0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mask = df_all_ids['is_train'].values\n",
    "\n",
    "features_content_names_train = features_content_names[mask]\n",
    "features_vacancy_info_train = features_vacancy_info[mask]\n",
    "features_employer_train = features_employer[mask]\n",
    "features_content_skills_train = features_content_skills[mask]\n",
    "vacancy_id_train = df_all_ids[mask].index.values\n",
    "  \n",
    "features_content_names_test = features_content_names[~mask]\n",
    "features_vacancy_info_test = features_vacancy_info[~mask]\n",
    "features_employer_test = features_employer[~mask]\n",
    "features_content_skills_test = features_content_skills[~mask]\n",
    "vacancy_id_test = df_all_ids[~mask].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UiNrUaNcP1S5"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class HeadHunterDataset(Dataset):\n",
    "    def __init__(self, content_names, vacancy_info, employer_info, skills_info, target,\n",
    "                 batch_size=100, shuffle=True, random_state=None):\n",
    "        self.check_shapes(\n",
    "            content_names,\n",
    "            vacancy_info,\n",
    "            employer_info,\n",
    "            skills_info,\n",
    "            target,\n",
    "        )\n",
    "\n",
    "        self.content_names = content_names\n",
    "        self.vacancy_info = vacancy_info\n",
    "        self.employer_info = employer_info\n",
    "        self.skills_info = skills_info\n",
    "        self.target = target\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        if random_state is not None and isinstance(random_state, np.random.RandomState):\n",
    "            self.random_state = random_state\n",
    "        else:\n",
    "            self.random_state = np.random.RandomState(random_state)\n",
    "\n",
    "        # init index\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def check_shapes(self, *args):\n",
    "        args = args[:-1] if args[-1] is None else args\n",
    "\n",
    "        shapes = map(lambda e: e.shape[0], args)\n",
    "        shapes = list(shapes)\n",
    "\n",
    "        # https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical\n",
    "\n",
    "        assert shapes.count(shapes[0]) == len(shapes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(math.ceil(self.content_names.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        index = self.index[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        batch_content_names = self.content_names[index]\n",
    "        batch_vacancy_info = self.vacancy_info[index]\n",
    "        batch_employer_info = self.employer_info[index]\n",
    "        batch_skills_info = self.skills_info[index]\n",
    "        \n",
    "        if self.target is not None:\n",
    "            batch_y = self.target[index]\n",
    "            batch_y = batch_y.toarray()\n",
    "        else:\n",
    "            # inference mode\n",
    "            batch_y = None\n",
    "\n",
    "        batch_x = (\n",
    "            batch_content_names.toarray(),\n",
    "            batch_vacancy_info.toarray(),\n",
    "            batch_employer_info.toarray(),\n",
    "            batch_skills_info.toarray(),\n",
    "        )\n",
    "\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.index = self.random_state.permutation(self.content_names.shape[0])\n",
    "        else:\n",
    "            self.index = np.arange(self.content_names.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "vnFdYXQKjWmG",
    "outputId": "746f60ec-1dc7-4507-d27c-7c8b7d09f0b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeadHunterNetworkEmployer(\n",
       "  (network): Sequential(\n",
       "    (0): Linear(in_features=416846, out_features=620, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class HeadHunterNetworkEmployer(nn.Module):\n",
    "    def __init__(self, num_content_names, num_vacancy_info, num_employer_info, num_skills_info, num_target):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_vacancy_info = num_vacancy_info is not None\n",
    "        self.use_employer_info = num_employer_info is not None\n",
    "        self.use_skills_info = num_skills_info is not None\n",
    "\n",
    "        num_features = [num_content_names, num_vacancy_info, num_employer_info, num_skills_info, ]\n",
    "        num_features = filter(lambda e: e is not None, num_features)\n",
    "        num_features = sum(num_features)\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                in_features=num_features,\n",
    "                out_features=num_target,\n",
    "                bias=True,\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, content_names, vacancy_info, employer_info, skills_info):\n",
    "        x = (content_names, )\n",
    "        \n",
    "        if self.use_vacancy_info:\n",
    "            x += (vacancy_info, )\n",
    "        \n",
    "        if self.use_employer_info:\n",
    "            x += (employer_info, )\n",
    "        \n",
    "        if self.use_skills_info:\n",
    "            x += (skills_info, )\n",
    "        \n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.network(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_3 = HeadHunterNetworkEmployer(\n",
    "    num_content_names=features_content_names.shape[1],\n",
    "    num_vacancy_info=features_vacancy_info.shape[1],\n",
    "    num_employer_info=features_employer.shape[1],\n",
    "    num_skills_info=features_content_skills.shape[1],\n",
    "    num_target=len(mapping_spec),\n",
    ")\n",
    "\n",
    "\n",
    "model_3_path = os.path.join(WORKDIR, 'models/model_logreg_017_empl_skills.pt')\n",
    "model_3.load_state_dict(torch.load(model_3_path, map_location=torch.device('cpu')))\n",
    "model_3.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-LFmLgLtKR5"
   },
   "outputs": [],
   "source": [
    "def to_tensor(X, use_cuda=False):\n",
    "    if not torch.is_tensor(X):\n",
    "        device = 'cuda' if use_cuda else 'cpu'\n",
    "        X = torch.tensor(X, device=device, dtype=torch.float32)\n",
    "\n",
    "    if use_cuda and not X.is_cuda:\n",
    "        X = X.cuda()\n",
    "\n",
    "    if not torch.is_floating_point(X):\n",
    "        X = X.float()\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RjfT-vX8s5kO"
   },
   "outputs": [],
   "source": [
    "input_train = HeadHunterDataset(\n",
    "    features_content_names_train, features_vacancy_info_train,\n",
    "    features_employer_train, features_content_skills_train, y_spec,\n",
    "    batch_size=1024, shuffle=False, random_state=42,\n",
    ")\n",
    "\n",
    "input_test = HeadHunterDataset(\n",
    "    features_content_names_test, features_vacancy_info_test,\n",
    "    features_employer_test, features_content_skills_test, None,\n",
    "    batch_size=1024, shuffle=False, random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ya50WB47qNXk",
    "outputId": "4089388c-7642-4d89-bacd-5b6e47af404e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RankedEntry(vacancy_id=-1, spec_id=-1, counts=0, min_tfidf=10, max_tfidf=-1, logreg_score=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "\n",
    "@dataclass\n",
    "class RankedEntry:\n",
    "    vacancy_id: int = -1\n",
    "    spec_id: int = -1\n",
    "    counts: int = 0\n",
    "    min_tfidf: float = 10\n",
    "    max_tfidf: float = -1\n",
    "    logreg_score: float = -1\n",
    "\n",
    "def create_candidates(num):\n",
    "    candidates = [defaultdict(RankedEntry) for _ in range(num)]\n",
    "    return candidates\n",
    "        \n",
    "RankedEntry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_train = create_candidates(features_content_names_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_test = create_candidates(features_content_names_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pG78qV4Om0cv"
   },
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_best = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_knn_candidates(candidates_new, top, tfidf):\n",
    "    for i, (k, v) in enumerate(candidates_new):\n",
    "        if i < top:\n",
    "            yield k, v\n",
    "        elif v.max_tfidf >= tfidf:\n",
    "            yield k, v\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "\n",
    "def add_knn_candidates(candidates, indices, ranks, labels):\n",
    "    for i in tqdm(range(indices.shape[0]), position=0):\n",
    "        candidates_row = defaultdict(RankedEntry)\n",
    "        \n",
    "        for j, tfidf in zip(indices[i], ranks[i]):\n",
    "            if j < 0:\n",
    "                break\n",
    "\n",
    "            for k in labels[j].indices:\n",
    "                e = candidates_row[k]\n",
    "\n",
    "                e.spec_id = k\n",
    "                e.min_tfidf = min(e.min_tfidf, tfidf)\n",
    "                e.max_tfidf = max(e.max_tfidf, tfidf)\n",
    "                e.counts += 1\n",
    "\n",
    "        candidates_new = sorted(candidates_row.items(), key=lambda p: p[1].counts, reverse=True)\n",
    "        candidates_new = choose_knn_candidates(candidates_new, top=15, tfidf=0.975)\n",
    "        candidates_new = defaultdict(RankedEntry, candidates_new)\n",
    "        \n",
    "        # choose all candidates from most similar object\n",
    "        index_first = indices[i, 0]\n",
    "        candidates_new.update({k: candidates_row[k] for k in labels[index_first].indices})\n",
    "\n",
    "        candidates_row = candidates[i]\n",
    "        \n",
    "        for k, v in candidates_new.items():\n",
    "            candidates_row[k].spec_id = k\n",
    "            candidates_row[k].min_tfidf = v.min_tfidf\n",
    "            candidates_row[k].max_tfidf = v.max_tfidf\n",
    "            candidates_row[k].counts = v.counts\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-6-_sUxmxCD"
   },
   "outputs": [],
   "source": [
    "indices_train_file = os.path.join(WORKDIR, 'data/neigbours-train-all.indices.npz')\n",
    "ranks_train_file = os.path.join(WORKDIR, 'data/neigbours-train-all.ranks.npz')\n",
    "\n",
    "indices_knn_train = load_array(indices_train_file, sparse=False)[:,:K_best]\n",
    "ranks_knn_train = load_array(ranks_train_file, sparse=False)[:,:K_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [28:39<00:00, 846.95it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8, 9, 19, 27, 7, 4, 6, 15, 15, 15, 15, 22, 16, 12, 13]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_train = add_knn_candidates(candidates_train, indices_knn_train, ranks_knn_train, y_spec)\n",
    "\n",
    "list(map(len, candidates_train[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t-JFCWW5zPh9"
   },
   "outputs": [],
   "source": [
    "del indices_knn_train, ranks_knn_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_test_file = os.path.join(WORKDIR, 'data/neigbours-test.indices.npz')\n",
    "ranks_test_file = os.path.join(WORKDIR, 'data/neigbours-test.ranks.npz')\n",
    "\n",
    "indices_knn_test = load_array(indices_test_file, sparse=False)[:,:K_best]\n",
    "ranks_knn_test = load_array(ranks_test_file, sparse=False)[:,:K_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [30:09<00:00, 804.83it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15, 7, 15, 15, 17, 26, 15, 14, 12, 12, 31, 30, 23, 16, 24]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_test = add_knn_candidates(candidates_test, indices_knn_test, ranks_knn_test, y_spec)\n",
    "\n",
    "list(map(len, candidates_test[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del indices_knn_test, ranks_knn_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poisk/.conda/envs/ml-py37/lib/python3.7/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>specializations</th>\n",
       "      <th>is_train</th>\n",
       "      <th>area_id</th>\n",
       "      <th>compensation_from</th>\n",
       "      <th>compensation_to</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>currency</th>\n",
       "      <th>employer</th>\n",
       "      <th>employment</th>\n",
       "      <th>work_experience</th>\n",
       "      <th>work_schedule</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vacancy_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>RUR</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-07-26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b9aa259f8724</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[211]</td>\n",
       "      <td>True</td>\n",
       "      <td>1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11ecc72a7a76</td>\n",
       "      <td>project</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[389, 412, 437]</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36000.0</td>\n",
       "      <td>2019-07-12</td>\n",
       "      <td>RUR</td>\n",
       "      <td>e1e424ceb5e4</td>\n",
       "      <td>full</td>\n",
       "      <td>noExperience</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1002</td>\n",
       "      <td>600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-17</td>\n",
       "      <td>BYR</td>\n",
       "      <td>943fd4a3770a</td>\n",
       "      <td>full</td>\n",
       "      <td>between1And3</td>\n",
       "      <td>fullDay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           specializations  is_train  area_id  \\\n",
       "vacancy_id                                                      \n",
       "1           [242, 256, 302, 324, 358, 440]      True       26   \n",
       "2                                      NaN     False      160   \n",
       "3                                    [211]      True     1002   \n",
       "4                          [389, 412, 437]      True       22   \n",
       "5                                      NaN     False     1002   \n",
       "\n",
       "            compensation_from  compensation_to creation_date currency  \\\n",
       "vacancy_id                                                              \n",
       "1                     22000.0          24000.0    2019-01-24      RUR   \n",
       "2                         NaN              NaN    2019-07-26      NaN   \n",
       "3                         NaN              NaN    2019-04-15      NaN   \n",
       "4                         NaN          36000.0    2019-07-12      RUR   \n",
       "5                       600.0              NaN    2019-01-17      BYR   \n",
       "\n",
       "                employer employment work_experience work_schedule  \n",
       "vacancy_id                                                         \n",
       "1           0ce23382345c       full    between1And3       fullDay  \n",
       "2           b9aa259f8724       full    between1And3       fullDay  \n",
       "3           11ecc72a7a76    project    between1And3       fullDay  \n",
       "4           e1e424ceb5e4       full    noExperience       fullDay  \n",
       "5           943fd4a3770a       full    between1And3       fullDay  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vacancies_file = os.path.join(WORKDIR, 'data/vacancies_info.csv.gz')\n",
    "\n",
    "df_all_ids = pd.read_csv(\n",
    "    vacancies_file,\n",
    "    index_col='vacancy_id',\n",
    "    compression='gzip',\n",
    ")\n",
    "\n",
    "df_all_ids.loc[df_all_ids['is_train'], 'specializations'] = \\\n",
    "    df_all_ids.loc[df_all_ids['is_train'], 'specializations'].map(parse_specializations)\n",
    "\n",
    "df_all_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_all_ids[df_all_ids['is_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_counter = Counter()\n",
    "employer_counters = defaultdict(lambda: Counter())\n",
    "\n",
    "for spec_list, employer_id in zip(df_train['specializations'], df_train['employer']):\n",
    "    for spec in spec_list:\n",
    "        spec = mapping_spec[spec]\n",
    "        common_counter[spec] += 1\n",
    "        employer_counters[employer_id][spec] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>89768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>119524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_id  counts\n",
       "0        0   89768\n",
       "1        1  119524\n",
       "2        2   36158\n",
       "3        3   42051\n",
       "4        4    6909"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_counter = pd.DataFrame([\n",
    "    {'spec_id': k, 'counts': v}\n",
    "    for k, v in common_counter.items()\n",
    "])\n",
    "common_counter.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>employer</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_id      employer  counts\n",
       "0        0  0ce23382345c      26\n",
       "1        1  0ce23382345c     205\n",
       "2        2  0ce23382345c      25\n",
       "3        3  0ce23382345c      28\n",
       "4        4  0ce23382345c       4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employer_counters = pd.DataFrame([\n",
    "    {'spec_id': spec_id, 'employer': employer_id, 'counts': e, }\n",
    "    for employer_id, v in employer_counters.items()\n",
    "    for spec_id, e in v.items()\n",
    "])\n",
    "employer_counters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_id</th>\n",
       "      <th>employer</th>\n",
       "      <th>counts</th>\n",
       "      <th>counts_glb</th>\n",
       "      <th>counts_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>26</td>\n",
       "      <td>89768</td>\n",
       "      <td>0.000290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>205</td>\n",
       "      <td>119524</td>\n",
       "      <td>0.001715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>25</td>\n",
       "      <td>36158</td>\n",
       "      <td>0.000691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>28</td>\n",
       "      <td>42051</td>\n",
       "      <td>0.000666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0ce23382345c</td>\n",
       "      <td>4</td>\n",
       "      <td>6909</td>\n",
       "      <td>0.000579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_id      employer  counts  counts_glb  counts_prob\n",
       "0        0  0ce23382345c      26       89768     0.000290\n",
       "1        1  0ce23382345c     205      119524     0.001715\n",
       "2        2  0ce23382345c      25       36158     0.000691\n",
       "3        3  0ce23382345c      28       42051     0.000666\n",
       "4        4  0ce23382345c       4        6909     0.000579"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_counters = pd.merge(employer_counters, common_counter, how='left', on='spec_id', suffixes=('', '_glb'))\n",
    "spec_counters['counts_prob'] = spec_counters['counts'] / spec_counters['counts_glb']\n",
    "spec_counters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employer</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003669d84d</td>\n",
       "      <td>273</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00005eb9ef63</td>\n",
       "      <td>316</td>\n",
       "      <td>0.000188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00005eb9ef63</td>\n",
       "      <td>204</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000a9f4dad5</td>\n",
       "      <td>343</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000a9f4dad5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employer  spec_id  counts_prob\n",
       "0  00003669d84d      273     0.000260\n",
       "1  00005eb9ef63      316     0.000188\n",
       "2  00005eb9ef63      204     0.000055\n",
       "3  0000a9f4dad5      343     0.000447\n",
       "4  0000a9f4dad5       11     0.000075"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_counters_top = spec_counters.groupby('employer').apply(\n",
    "    lambda g: g.sort_values(by='counts_prob', ascending=False).set_index('spec_id')[:6]['counts_prob'])\n",
    "spec_counters_top = spec_counters_top.reset_index()\n",
    "spec_counters_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256539/256539 [00:47<00:00, 5372.26it/s]\n"
     ]
    }
   ],
   "source": [
    "spec_counters_top = {name: group['spec_id'].tolist()\n",
    "                     for name, group in tqdm(spec_counters_top.groupby('employer'), position=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_counter_candidates(candidates, vacancy_ids):\n",
    "    assert len(candidates) == len(vacancy_ids)\n",
    "    \n",
    "    for candidates_row, vacancy_id in tqdm(zip(candidates, vacancy_ids), position=0, total=len(candidates)):\n",
    "        employer = df_all_ids.loc[vacancy_id, 'employer']\n",
    "        \n",
    "        if employer not in spec_counters_top:\n",
    "            continue\n",
    "        \n",
    "        for spec_id in spec_counters_top[employer]:\n",
    "            e = candidates_row[spec_id]\n",
    "            e.spec_id = spec_id\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [00:32<00:00, 44234.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14, 12, 19, 32, 7, 9, 12, 21, 16, 15, 21, 28, 22, 18, 17]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_train = add_counter_candidates(candidates_train, vacancy_id_train)\n",
    "\n",
    "list(map(len, candidates_train[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [00:42<00:00, 34060.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[21, 11, 15, 19, 21, 26, 21, 18, 15, 17, 37, 35, 28, 17, 27]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_test = add_counter_candidates(candidates_test, vacancy_id_test)\n",
    "\n",
    "list(map(len, candidates_test[:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5y4swvgt1mE"
   },
   "source": [
    "# LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_ranks(ranks: np.ndarray, top: int, axis: int = 0, return_ranks: bool = False):\n",
    "    top_slice = (slice(None), ) * axis + (slice(-top, None), )\n",
    "    inv_slice = (slice(None), ) * axis + (slice(None, None, -1), )\n",
    "\n",
    "    if top < ranks.shape[axis]:\n",
    "        indices = np.argpartition(ranks, -top, axis=axis)[top_slice]\n",
    "        ranks_top = np.take_along_axis(ranks, indices, axis=axis)\n",
    "        indices = np.take_along_axis(indices, ranks_top.argsort(axis=axis)[inv_slice], axis=axis)\n",
    "    else:\n",
    "        indices = np.argsort(ranks, axis=axis)[top_slice]\n",
    "        indices = indices[inv_slice]\n",
    "\n",
    "    result = (indices, )\n",
    "\n",
    "    if return_ranks:\n",
    "        ranks = np.take_along_axis(ranks, indices, axis=axis)\n",
    "        result += (ranks, )\n",
    "\n",
    "    return result if len(result) > 1 else result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_unknown_scores(candidates, model, input_seq, top=6):\n",
    "    j_min = 0\n",
    "\n",
    "    for i in tqdm(range(len(input_seq)), position=0, leave=True):\n",
    "        X_batch, _ = input_seq[i]\n",
    "\n",
    "        y_batch = model(*map(to_tensor, X_batch))\n",
    "        y_batch = y_batch.cpu().detach().numpy()\n",
    "\n",
    "        for j in range(0, y_batch.shape[0]):\n",
    "            candidates_row = candidates[j + j_min]\n",
    "            indices = [k for k, v in candidates_row.items() if v.logreg_score < 0]\n",
    "            ranks = y_batch[j, indices]\n",
    "\n",
    "            for k, prob in zip(indices, ranks):\n",
    "                candidates_row[k].logreg_score = prob\n",
    "\n",
    "        indices_batch = get_best_ranks(y_batch, top=top, axis=1, return_ranks=False)\n",
    "        \n",
    "        for j in range(0, y_batch.shape[0]):\n",
    "            candidates_row = candidates[j + j_min]\n",
    "            \n",
    "            indices = indices_batch[j]\n",
    "            ranks = y_batch[j, indices]\n",
    "            \n",
    "            for k, prob in zip(indices, ranks):\n",
    "                candidates_row[k].logreg_score = prob\n",
    "\n",
    "        j_min += y_batch.shape[0]\n",
    "        \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5689/5689 [29:06<00:00,  3.26it/s]\n"
     ]
    }
   ],
   "source": [
    "candidates_train = fill_unknown_scores(candidates_train, model_3, input_train, top=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FyaoexA8Pf2L",
    "outputId": "3359df94-b5dd-4f17-d9ce-771f85942d9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 13, 21, 33, 8, 13, 14, 23, 16, 17, 21, 28, 24, 18, 17]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, candidates_train[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 13., 15., 17., 18., 20., 21., 23., 26.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile([len(c) for c in candidates_train], q=np.arange(0.1, 1.0, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1423/1423 [24:44<00:00,  1.04s/it]\n"
     ]
    }
   ],
   "source": [
    "candidates_test = fill_unknown_scores(candidates_test, model_3, input_test, top=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 11, 16, 19, 21, 28, 23, 18, 15, 19, 38, 36, 28, 17, 27]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, candidates_test[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11., 13., 15., 17., 18., 20., 21., 23., 26.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile([len(c) for c in candidates_test], q=np.arange(0.1, 1.0, 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ne59lsFxRP9"
   },
   "source": [
    "# Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RthoKLET8VY1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1426"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4491645"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pairs = df_all_ids.loc[vacancy_id_train, 'specializations'].reset_index()\n",
    "train_pairs = {(k, e) for k, v in zip(train_pairs['vacancy_id'], train_pairs['specializations']) for e in v}\n",
    "\n",
    "len(train_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620, 257995)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset = features_content_names.shape[1] + features_vacancy_info.shape[1]\n",
    "\n",
    "weights = model_3.state_dict()['network.0.weight'].detach().numpy()\n",
    "weights = weights[:, offset:offset+features_employer.shape[1]]\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "from dask.dataframe.utils import make_meta\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "\n",
    "def add_ranks(group, cols):\n",
    "    ranks = group[cols].rank(axis=0, method='average', ascending=False).add_prefix('rank_')\n",
    "    group = pd.concat([group, ranks], axis=1)\n",
    "    return group\n",
    "\n",
    "\n",
    "def create_ranking_df(vacancy_ids, candidates, rank_cols=None, use_logreg_weights=True):\n",
    "    df_ranking = []\n",
    "\n",
    "    candidates_zip = zip(vacancy_ids, candidates)\n",
    "    candidates_zip = tqdm(candidates_zip, position=0, total=len(candidates))\n",
    "\n",
    "    for vacancy_id, candidates_row in candidates_zip:\n",
    "        for candidate in candidates_row.values():\n",
    "            candidate = asdict(candidate)\n",
    "            candidate['vacancy_id'] = vacancy_id\n",
    "            df_ranking.append(candidate)\n",
    "\n",
    "    df_ranking = pd.DataFrame(df_ranking)\n",
    "    \n",
    "    # prepare employer column for future features\n",
    "    df_ranking = pd.merge(\n",
    "        df_ranking,\n",
    "        df_all_ids[['employer']].reset_index(),\n",
    "        how='left',\n",
    "        on='vacancy_id', \n",
    "    )\n",
    "\n",
    "    # use counts for (spec_id, employer)\n",
    "    df_ranking = pd.merge(\n",
    "        df_ranking,\n",
    "        spec_counters[['spec_id', 'employer', 'counts_prob']],\n",
    "        how='left',\n",
    "        on=['spec_id', 'employer'],\n",
    "    )\n",
    "    \n",
    "    df_ranking['counts_prob'] = df_ranking['counts_prob'].fillna(0)\n",
    "    \n",
    "    # use logreg weights for (spec_id, employer)\n",
    "    if use_logreg_weights:\n",
    "        df_ranking['employer_logreg'] = df_ranking['employer'].map(\n",
    "            lambda e: mapping_employer.get(e, mapping_employer['UNKNOWN'])\n",
    "        )\n",
    "        \n",
    "        index = df_ranking[['spec_id', 'employer_logreg']].values\n",
    "        index = (index[:,0], index[:,1], )\n",
    "        df_ranking['logreg_employer_weight'] = weights[index]\n",
    "\n",
    "        df_ranking.drop(columns=['employer_logreg'], inplace=True)\n",
    "        \n",
    "    # use ranks\n",
    "    if rank_cols:\n",
    "        df_ranking = df_ranking.set_index('vacancy_id')\n",
    "        \n",
    "        meta = make_meta(df_ranking)\n",
    "        for col in rank_cols:\n",
    "            col = 'rank_' + col\n",
    "            meta[col] = pd.Series(name=col, dtype='float')\n",
    "        \n",
    "        with ProgressBar():\n",
    "            df_ranking = df_ranking.pipe(dd.from_pandas, npartitions=100)\\\n",
    "                                   .groupby('vacancy_id')\\\n",
    "                                   .apply(lambda g: add_ranks(g, rank_cols), meta=meta)\\\n",
    "                                   .compute(num_workers=20)\n",
    "\n",
    "        \"\"\"\n",
    "        df_groups = []\n",
    "        for _, group in tqdm(df_ranking.groupby('vacancy_id'), position=0):\n",
    "            group = add_ranks(group, rank_cols)\n",
    "            df_groups.append(group)\n",
    "        df_ranking = pd.concat(df_groups, axis=0)\n",
    "        \"\"\"\n",
    "    \n",
    "    # remove redundant columns\n",
    "    df_ranking.drop(columns=['employer'], inplace=True)\n",
    "\n",
    "    df_ranking['spec_id'] = df_ranking['spec_id'].map(lambda e: mapping_spec_inv[e])\n",
    "    df_ranking.sort_index(inplace=True)\n",
    "\n",
    "    return df_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1fUx5hxOxPpT",
    "outputId": "366dea6f-22ad-485e-dcba-287c9df20905"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [09:51<00:00, 2463.81it/s]\n",
      "100%|██████████| 1456325/1456325 [56:35<00:00, 428.92it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 24min 55s, sys: 4min 30s, total: 1h 29min 25s\n",
      "Wall time: 1h 29min 9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>min_tfidf</th>\n",
       "      <th>max_tfidf</th>\n",
       "      <th>logreg_score</th>\n",
       "      <th>counts_prob</th>\n",
       "      <th>logreg_employer_weight</th>\n",
       "      <th>rank_counts</th>\n",
       "      <th>rank_counts_prob</th>\n",
       "      <th>rank_logreg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609589</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.312096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914891</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>1.468223</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.231966</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648414</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.122485</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516882</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.116580</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id  spec_id  counts  min_tfidf  max_tfidf  logreg_score  \\\n",
       "0           1      242      12        1.0        1.0      0.609589   \n",
       "1           1      256      11        1.0        1.0      0.914891   \n",
       "2           1      324      11        1.0        1.0      0.776175   \n",
       "3           1      302      10        1.0        1.0      0.648414   \n",
       "4           1      440       8        1.0        1.0      0.516882   \n",
       "\n",
       "   counts_prob  logreg_employer_weight  rank_counts  rank_counts_prob  \\\n",
       "0     0.000290               -0.312096          1.0              12.0   \n",
       "1     0.001715                1.468223          2.5               7.0   \n",
       "2     0.000666                0.231966          2.5              10.0   \n",
       "3     0.000691                0.122485          4.0               8.0   \n",
       "4     0.000670               -0.116580          5.0               9.0   \n",
       "\n",
       "   rank_logreg_score  \n",
       "0                4.0  \n",
       "1                1.0  \n",
       "2                2.0  \n",
       "3                3.0  \n",
       "4                5.0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_ranking_train = create_ranking_df(\n",
    "    vacancy_id_train, candidates_train,\n",
    "    rank_cols=['counts', 'counts_prob', 'logreg_score'],\n",
    "    use_logreg_weights=True,\n",
    ")\n",
    "df_ranking_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26751060, 11)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranking_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>min_tfidf</th>\n",
       "      <th>max_tfidf</th>\n",
       "      <th>logreg_score</th>\n",
       "      <th>counts_prob</th>\n",
       "      <th>logreg_employer_weight</th>\n",
       "      <th>rank_counts</th>\n",
       "      <th>rank_counts_prob</th>\n",
       "      <th>rank_logreg_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609589</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.312096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914891</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>1.468223</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.231966</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648414</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.122485</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516882</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.116580</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id  spec_id  counts  min_tfidf  max_tfidf  logreg_score  \\\n",
       "0           1      242      12        1.0        1.0      0.609589   \n",
       "1           1      256      11        1.0        1.0      0.914891   \n",
       "2           1      324      11        1.0        1.0      0.776175   \n",
       "3           1      302      10        1.0        1.0      0.648414   \n",
       "4           1      440       8        1.0        1.0      0.516882   \n",
       "\n",
       "   counts_prob  logreg_employer_weight  rank_counts  rank_counts_prob  \\\n",
       "0     0.000290               -0.312096          1.0              12.0   \n",
       "1     0.001715                1.468223          2.5               7.0   \n",
       "2     0.000666                0.231966          2.5              10.0   \n",
       "3     0.000691                0.122485          4.0               8.0   \n",
       "4     0.000670               -0.116580          5.0               9.0   \n",
       "\n",
       "   rank_logreg_score  target  \n",
       "0                4.0       1  \n",
       "1                1.0       1  \n",
       "2                2.0       1  \n",
       "3                3.0       1  \n",
       "4                5.0       1  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranking_train['target'] = [p in train_pairs\n",
    "                              for p in zip(df_ranking_train['vacancy_id'], df_ranking_train['spec_id'])]\n",
    "df_ranking_train['target'] = df_ranking_train['target'].astype(int)\n",
    "\n",
    "df_ranking_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vacancies: 1456325\n",
      "Number of vacancies (pos): 1418555\n",
      "Fraction of vacancies (pos): 0.974065\n",
      "[########################################] | 100% Completed |  9min  9.5s\n",
      "Recall: 0.897708\n",
      "CPU times: user 10min 14s, sys: 31.3 s, total: 10min 45s\n",
      "Wall time: 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import swifter\n",
    "\n",
    "def check_dataset_quality(df_ranking):\n",
    "    counts = df_ranking.groupby('vacancy_id')['target'].sum() > 0\n",
    "\n",
    "    print('Number of vacancies:', counts.shape[0])\n",
    "    print('Number of vacancies (pos):', counts.sum())\n",
    "    print('Fraction of vacancies (pos):', '%.6f' % (counts.sum() / counts.shape[0]))\n",
    "    \n",
    "    with ProgressBar():\n",
    "        counts = df_ranking.set_index('vacancy_id')\\\n",
    "                           .pipe(dd.from_pandas, npartitions=100)\\\n",
    "                           .groupby('vacancy_id')\\\n",
    "                           .apply(lambda g: g.loc[g['target'] > 0, 'spec_id'].tolist(), meta=('list'))\\\n",
    "                           .compute(num_workers=20)\n",
    "\n",
    "    counts = counts.rename('spec_id').reset_index()\n",
    "    \n",
    "#     counts = df_ranking.groupby('vacancy_id').apply(\n",
    "#         lambda g: g.loc[g['target'] > 0, 'spec_id'].tolist()\n",
    "#     ).rename('spec_id').reset_index()\n",
    "    \n",
    "    counts = pd.merge(\n",
    "        counts,\n",
    "        df_all_ids['specializations'].reset_index(),\n",
    "        on='vacancy_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    counts['specializations'] = counts['specializations'].swifter.progress_bar(False).apply(set)\n",
    "    counts['spec_id'] = counts['spec_id'].swifter.progress_bar(False).apply(set)\n",
    "    \n",
    "    counts_inter = counts.swifter.progress_bar(False).apply(\n",
    "        lambda r: len(r['specializations'] & r['spec_id']) / len(r['specializations']),\n",
    "        axis=1,\n",
    "    )\n",
    "    \n",
    "    print('Recall:', '%.6f' % counts_inter.mean())\n",
    "\n",
    "\n",
    "check_dataset_quality(df_ranking_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>min_tfidf</th>\n",
       "      <th>max_tfidf</th>\n",
       "      <th>logreg_score</th>\n",
       "      <th>counts_prob</th>\n",
       "      <th>logreg_employer_weight</th>\n",
       "      <th>rank_counts</th>\n",
       "      <th>rank_counts_prob</th>\n",
       "      <th>rank_logreg_score</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609589</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.312096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.914891</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>1.468223</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>324</td>\n",
       "      <td>11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.231966</td>\n",
       "      <td>2.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.648414</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.122485</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>440</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516882</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.116580</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id  spec_id  counts  min_tfidf  max_tfidf  logreg_score  \\\n",
       "0           1      242      12        1.0        1.0      0.609589   \n",
       "1           1      256      11        1.0        1.0      0.914891   \n",
       "2           1      324      11        1.0        1.0      0.776175   \n",
       "3           1      302      10        1.0        1.0      0.648414   \n",
       "4           1      440       8        1.0        1.0      0.516882   \n",
       "\n",
       "   counts_prob  logreg_employer_weight  rank_counts  rank_counts_prob  \\\n",
       "0     0.000290               -0.312096          1.0              12.0   \n",
       "1     0.001715                1.468223          2.5               7.0   \n",
       "2     0.000666                0.231966          2.5              10.0   \n",
       "3     0.000691                0.122485          4.0               8.0   \n",
       "4     0.000670               -0.116580          5.0               9.0   \n",
       "\n",
       "   rank_logreg_score  target  \n",
       "0                4.0       1  \n",
       "1                1.0       1  \n",
       "2                2.0       1  \n",
       "3                3.0       1  \n",
       "4                5.0       1  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_train_file = os.path.join(WORKDIR, 'data/ranking-dataset-train.csv.gz')\n",
    "\n",
    "df_ranking_train.to_csv(ranking_train_file, index=False, compression='gzip')\n",
    "df_ranking_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacancy_id,spec_id,counts,min_tfidf,max_tfidf,logreg_score,counts_prob,logreg_employer_weight,rank_counts,rank_counts_prob,rank_logreg_score,target\r\n",
      "1,242,12,1.0,1.0,0.6095885038375854,0.0002896355048569646,-0.312096,1.0,12.0,4.0,1\r\n",
      "1,256,11,1.0,1.0,0.9148905873298645,0.0017151367089454838,1.4682232,2.5,7.0,1.0,1\r\n",
      "1,324,11,1.0,1.0,0.7761746048927307,0.0006658581246581532,0.23196599,2.5,10.0,2.0,1\r\n",
      "1,302,10,1.0,1.0,0.6484136581420898,0.0006914099231152166,0.12248501,4.0,8.0,3.0,1\r\n",
      "1,440,8,1.0,1.0,0.516882061958313,0.000670391061452514,-0.11657994,5.0,9.0,5.0,1\r\n",
      "1,358,6,1.0,1.0,0.2547731399536133,0.000578954986249819,-1.0417575,6.0,11.0,7.0,1\r\n",
      "1,418,2,1.0,1.0,0.0003808138717431575,0.0,-2.3862836,7.0,14.0,12.0,0\r\n",
      "1,196,1,1.0,1.0,0.0015391720226034522,3.2814858567959574e-05,-2.7771082,8.0,13.0,10.0,0\r\n",
      "1,260,0,10.0,-1.0,0.0005034298519603908,0.005747126436781609,0.3474858,11.5,1.0,11.0,0\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat \"{ranking_train_file}\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1456325/1456325 [09:17<00:00, 2611.03it/s]\n",
      "/home/poisk/.conda/envs/ml-py37/lib/python3.7/site-packages/ipykernel_launcher.py:57: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 21min 6s, sys: 4min 8s, total: 1h 25min 15s\n",
      "Wall time: 1h 25min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>min_tfidf</th>\n",
       "      <th>max_tfidf</th>\n",
       "      <th>logreg_score</th>\n",
       "      <th>counts_prob</th>\n",
       "      <th>logreg_employer_weight</th>\n",
       "      <th>rank_counts</th>\n",
       "      <th>rank_counts_prob</th>\n",
       "      <th>rank_logreg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>9</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.401377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.037860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.099528</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.442375</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>395</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220978</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>388</td>\n",
       "      <td>3</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.038150</td>\n",
       "      <td>5.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id  spec_id  counts  min_tfidf  max_tfidf  logreg_score  \\\n",
       "0           2      211       9    0.66391    0.66391      0.401377   \n",
       "1           2      172       4    0.66391    0.66391      0.037860   \n",
       "2           2      420       4    0.66391    0.66391      0.027227   \n",
       "3           2      395       4    0.66391    0.66391      0.052264   \n",
       "4           2      388       3    0.66391    0.66391      0.006271   \n",
       "\n",
       "   counts_prob  logreg_employer_weight  rank_counts  rank_counts_prob  \\\n",
       "0          0.0               -0.169150          1.0              15.5   \n",
       "1          0.0               -0.099528          3.0              15.5   \n",
       "2          0.0               -0.442375          3.0              15.5   \n",
       "3          0.0               -0.220978          3.0              15.5   \n",
       "4          0.0               -0.038150          5.5              15.5   \n",
       "\n",
       "   rank_logreg_score  \n",
       "0                1.0  \n",
       "1                8.0  \n",
       "2                9.0  \n",
       "3                6.0  \n",
       "4               16.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df_ranking_test = create_ranking_df(\n",
    "    vacancy_id_test, candidates_test,\n",
    "    rank_cols=['counts', 'counts_prob', 'logreg_score'],\n",
    "    use_logreg_weights=True,\n",
    ")\n",
    "df_ranking_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26802688, 11)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ranking_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vacancy_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>counts</th>\n",
       "      <th>min_tfidf</th>\n",
       "      <th>max_tfidf</th>\n",
       "      <th>logreg_score</th>\n",
       "      <th>counts_prob</th>\n",
       "      <th>logreg_employer_weight</th>\n",
       "      <th>rank_counts</th>\n",
       "      <th>rank_counts_prob</th>\n",
       "      <th>rank_logreg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>9</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.401377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169150</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.037860</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.099528</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>420</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.442375</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>395</td>\n",
       "      <td>4</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.052264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220978</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>388</td>\n",
       "      <td>3</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.66391</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.038150</td>\n",
       "      <td>5.5</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vacancy_id  spec_id  counts  min_tfidf  max_tfidf  logreg_score  \\\n",
       "0           2      211       9    0.66391    0.66391      0.401377   \n",
       "1           2      172       4    0.66391    0.66391      0.037860   \n",
       "2           2      420       4    0.66391    0.66391      0.027227   \n",
       "3           2      395       4    0.66391    0.66391      0.052264   \n",
       "4           2      388       3    0.66391    0.66391      0.006271   \n",
       "\n",
       "   counts_prob  logreg_employer_weight  rank_counts  rank_counts_prob  \\\n",
       "0          0.0               -0.169150          1.0              15.5   \n",
       "1          0.0               -0.099528          3.0              15.5   \n",
       "2          0.0               -0.442375          3.0              15.5   \n",
       "3          0.0               -0.220978          3.0              15.5   \n",
       "4          0.0               -0.038150          5.5              15.5   \n",
       "\n",
       "   rank_logreg_score  \n",
       "0                1.0  \n",
       "1                8.0  \n",
       "2                9.0  \n",
       "3                6.0  \n",
       "4               16.0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranking_test_file = os.path.join(WORKDIR, 'data/ranking-dataset-test.csv.gz')\n",
    "\n",
    "df_ranking_test.to_csv(ranking_test_file, index=False, compression='gzip')\n",
    "df_ranking_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vacancy_id,spec_id,counts,min_tfidf,max_tfidf,logreg_score,counts_prob,logreg_employer_weight,rank_counts,rank_counts_prob,rank_logreg_score\r\n",
      "2,211,9,0.6639101832957769,0.6639101832957769,0.4013766050338745,0.0,-0.16915032,1.0,15.5,1.0\r\n",
      "2,172,4,0.6639101832957769,0.6639101832957769,0.03786018490791321,0.0,-0.09952811,3.0,15.5,8.0\r\n",
      "2,420,4,0.6639101832957769,0.6639101832957769,0.02722705341875553,0.0,-0.4423752,3.0,15.5,9.0\r\n",
      "2,395,4,0.6639101832957769,0.6639101832957769,0.05226431414484978,0.0,-0.22097787,3.0,15.5,6.0\r\n",
      "2,388,3,0.6639101832957769,0.6639101832957769,0.0062707820907235146,0.0,-0.038149506,5.5,15.5,16.0\r\n",
      "2,82,3,0.6639101832957769,0.6639101832957769,0.13734538853168488,0.0,-0.29671356,5.5,15.5,3.0\r\n",
      "2,93,2,0.6639101832957769,0.6639101832957769,0.009908813051879406,0.0,-0.029291844,9.5,15.5,14.0\r\n",
      "2,181,2,0.6639101832957769,0.6639101832957769,0.018524378538131714,0.0,-0.07971368,9.5,15.5,10.0\r\n",
      "2,278,2,0.6639101832957769,0.6639101832957769,0.038337696343660355,0.0,-0.095194176,9.5,15.5,7.0\r\n",
      "\r\n",
      "gzip: stdout: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!zcat \"{ranking_test_file}\" | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "\n",
    "def choose_best_scores_from_group(group, col_rank, top=6, threshold=None):\n",
    "    group = group.sort_values(col_rank, ascending=False)\n",
    "    group = group.iloc[:top]\n",
    "    if threshold is not None:\n",
    "        mask = (group[col_rank] > threshold).ravel()\n",
    "        mask[0] = True\n",
    "        group = group[mask]\n",
    "    return group['spec_id'].tolist()\n",
    "\n",
    "\n",
    "def make_dummy_prediction(df_ranking, col_rank, top=3):\n",
    "    ranking_dummy = partial(choose_best_scores_from_group, col_rank=col_rank, top=top, threshold=None)\n",
    "    df_predict = df_ranking.set_index('vacancy_id')\\\n",
    "                           .pipe(dd.from_pandas, npartitions=100)\\\n",
    "                           .groupby('vacancy_id')\\\n",
    "                           .apply(ranking_dummy, meta=('list'))\\\n",
    "                           .compute(num_workers=10)\n",
    "    df_predict = df_predict.rename('specializations').reset_index()\n",
    "    return df_predict\n",
    "\n",
    "\n",
    "def make_smart_prediction(df_ranking, col_rank, threshold, top=6):\n",
    "    ranking_smart = partial(choose_best_scores_from_group, col_rank=col_rank, top=top, threshold=threshold)\n",
    "    df_predict = df_ranking.set_index('vacancy_id')\\\n",
    "                           .pipe(dd.from_pandas, npartitions=100)\\\n",
    "                           .groupby('vacancy_id')\\\n",
    "                           .apply(ranking_smart, meta=('list'))\\\n",
    "                           .compute(num_workers=10)\n",
    "    df_predict = df_predict.rename('specializations').reset_index()\n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "submission_id = 15\n",
    "submission_file = os.path.join(WORKDIR, 'submission_{:03d}_check.csv.gz').format(submission_id)\n",
    "\n",
    "with ProgressBar():\n",
    "    df_submission = make_dummy_prediction(df_ranking_test, col='logreg_score')\n",
    "    df_submission.to_csv(submission_file, index=True, compression='gzip')\n",
    "    df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "submission_id = 11\n",
    "submission_file = os.path.join(WORKDIR, 'submission_{:03d}_check.csv.gz').format(submission_id)\n",
    "\n",
    "with ProgressBar():\n",
    "    df_submission = make_dummy_prediction(df_ranking_test, col='counts')\n",
    "    df_submission.to_csv(submission_file, index=True, compression='gzip')\n",
    "    df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3_merge_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
