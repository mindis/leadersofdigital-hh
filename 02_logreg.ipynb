{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4-logreg-smart-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmvMP7rF8toU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZQjUfMxNnxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pymorphy2\n",
        "!python -m nltk.downloader stopwords\n",
        "!python -m nltk.downloader wordnet\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLRafaC0LC_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVC0QR09LGOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "import json\n",
        "import gzip\n",
        "import codecs\n",
        "\n",
        "from itertools import islice, chain, filterfalse\n",
        "from collections import Counter, defaultdict\n",
        "from operator import itemgetter\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import pandas as pd\n",
        "\n",
        "import lxml.html as lhtml\n",
        "\n",
        "# from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jowRezzeKkOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkkEzd9lLG20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WORKDIR = '/content/drive/My Drive/round2-hh'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF37F2YVzsh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p \"{WORKDIR}/data\" \"{WORKDIR}/models\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pANZ8vyrwCgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_array(a, filename: str, sparse: bool = False, **params):\n",
        "    if sparse and not sp.issparse(a):\n",
        "        a = sp.csr_matrix(a)\n",
        "    elif not sparse and sp.issparse(a):\n",
        "        a = np.asarray(a.todense())\n",
        "\n",
        "    with open(filename, 'wb') as f_data:\n",
        "        save = sp.save_npz if sparse else np.save\n",
        "        return save(f_data, a, **params)\n",
        "\n",
        "\n",
        "def load_array(filename: str, sparse: bool = False, **params):\n",
        "    with open(filename, 'rb') as f_data:\n",
        "        load = sp.load_npz if sparse else np.load\n",
        "        return load(f_data, **params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_74JYgdUYYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "7ffe6ca1-a21c-47ac-d0c2-45a26fb274ae"
      },
      "source": [
        "def parse_specializations(s):\n",
        "    res = s[1:-1].split(',')\n",
        "    res = map(int, res)\n",
        "    res = list(res)\n",
        "    # res = np.asarray(res, dtype=int)\n",
        "    return res\n",
        "\n",
        "vacancies_file = os.path.join(WORKDIR, 'data/vacancies_info.csv.gz')\n",
        "\n",
        "if not os.path.isfile(vacancies_file):\n",
        "    # Загружаем специализации для обучения\n",
        "    df_train_ids = pd.read_csv(\n",
        "        os.path.join(WORKDIR, 'train_labels.csv.gz'),\n",
        "        index_col='vacancy_id',\n",
        "        compression='gzip',\n",
        "    )\n",
        "\n",
        "    df_train_ids['specializations'] = df_train_ids['specializations'].map(parse_specializations)\n",
        "    df_train_ids['is_train'] = True\n",
        "\n",
        "    # Загружаем специализации для теста\n",
        "    df_test_ids = pd.read_csv(\n",
        "        os.path.join(WORKDIR, 'test_vacancy_ids.csv.gz'),\n",
        "        index_col='vacancy_id',\n",
        "        compression='gzip',\n",
        "    )\n",
        "\n",
        "    # Объединяем в один датафрейм\n",
        "    df_all_ids = pd.concat([df_train_ids, df_test_ids], axis=0)\n",
        "    df_all_ids['is_train'].fillna(False, inplace=True)\n",
        "    df_all_ids.sort_index(inplace=True)\n",
        "\n",
        "    # Загружаем информацию о каждой из вакансий\n",
        "    df_vacancies_info = pd.read_csv(\n",
        "        os.path.join(WORKDIR, 'vacancies_info.csv.gz'),\n",
        "        index_col='vacancy_id',\n",
        "        compression='gzip',\n",
        "    )\n",
        "\n",
        "    # Объединяем в один датафрейм\n",
        "    df_all_ids = pd.merge(df_all_ids, df_vacancies_info, left_index=True, right_index=True, how='left')\n",
        "\n",
        "    df_all_ids.to_csv(vacancies_file, index=True, compression='gzip')\n",
        "else:\n",
        "    df_all_ids = pd.read_csv(\n",
        "        vacancies_file,\n",
        "        index_col='vacancy_id',\n",
        "        compression='gzip',\n",
        "    )\n",
        "    df_all_ids.loc[df_all_ids['is_train'], 'specializations'] = \\\n",
        "        df_all_ids.loc[df_all_ids['is_train'], 'specializations'].map(parse_specializations)\n",
        "\n",
        "df_all_ids.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
            "  mask |= (ar1 == a)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>specializations</th>\n",
              "      <th>is_train</th>\n",
              "      <th>area_id</th>\n",
              "      <th>compensation_from</th>\n",
              "      <th>compensation_to</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>currency</th>\n",
              "      <th>employer</th>\n",
              "      <th>employment</th>\n",
              "      <th>work_experience</th>\n",
              "      <th>work_schedule</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vacancy_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>2019-01-24</td>\n",
              "      <td>RUR</td>\n",
              "      <td>0ce23382345c</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>160</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-07-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b9aa259f8724</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[211]</td>\n",
              "      <td>True</td>\n",
              "      <td>1002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-04-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11ecc72a7a76</td>\n",
              "      <td>project</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[389, 412, 437]</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>2019-07-12</td>\n",
              "      <td>RUR</td>\n",
              "      <td>e1e424ceb5e4</td>\n",
              "      <td>full</td>\n",
              "      <td>noExperience</td>\n",
              "      <td>fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>1002</td>\n",
              "      <td>600.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>BYR</td>\n",
              "      <td>943fd4a3770a</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           specializations  ...  work_schedule\n",
              "vacancy_id                                  ...               \n",
              "1           [242, 256, 302, 324, 358, 440]  ...        fullDay\n",
              "2                                      NaN  ...        fullDay\n",
              "3                                    [211]  ...        fullDay\n",
              "4                          [389, 412, 437]  ...        fullDay\n",
              "5                                      NaN  ...        fullDay\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYTVqw_pCgrk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "8bb24ec8-4668-417d-d81b-18cfc8100f6f"
      },
      "source": [
        "df_all_ids['joined_work'] = (\n",
        "    df_all_ids['employment'] + '_' +\n",
        "    df_all_ids['work_experience'] + '_' +\n",
        "    df_all_ids['work_schedule']\n",
        ")\n",
        "\n",
        "df_all_ids.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>specializations</th>\n",
              "      <th>is_train</th>\n",
              "      <th>area_id</th>\n",
              "      <th>compensation_from</th>\n",
              "      <th>compensation_to</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>currency</th>\n",
              "      <th>employer</th>\n",
              "      <th>employment</th>\n",
              "      <th>work_experience</th>\n",
              "      <th>work_schedule</th>\n",
              "      <th>joined_work</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vacancy_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>2019-01-24</td>\n",
              "      <td>RUR</td>\n",
              "      <td>0ce23382345c</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>160</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-07-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b9aa259f8724</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[211]</td>\n",
              "      <td>True</td>\n",
              "      <td>1002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-04-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11ecc72a7a76</td>\n",
              "      <td>project</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>project_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[389, 412, 437]</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>2019-07-12</td>\n",
              "      <td>RUR</td>\n",
              "      <td>e1e424ceb5e4</td>\n",
              "      <td>full</td>\n",
              "      <td>noExperience</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_noExperience_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>1002</td>\n",
              "      <td>600.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>BYR</td>\n",
              "      <td>943fd4a3770a</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           specializations  ...                   joined_work\n",
              "vacancy_id                                  ...                              \n",
              "1           [242, 256, 302, 324, 358, 440]  ...     full_between1And3_fullDay\n",
              "2                                      NaN  ...     full_between1And3_fullDay\n",
              "3                                    [211]  ...  project_between1And3_fullDay\n",
              "4                          [389, 412, 437]  ...     full_noExperience_fullDay\n",
              "5                                      NaN  ...     full_between1And3_fullDay\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRLpSLHOp6Gc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d38e8156-2e22-4529-c47c-af494a599bed"
      },
      "source": [
        "features_vacancy_info = pd.get_dummies(df_all_ids[['employment', 'work_experience', 'work_schedule']], sparse=True)\n",
        "\n",
        "# features_vacancy_info = pd.get_dummies(df_all_ids['joined_work'], sparse=True)\n",
        "features_vacancy_info = features_vacancy_info.sparse.to_coo().tocsr()\n",
        "features_vacancy_info.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2912650, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOBjiCFP7YOG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d162fa1-a575-4484-e8de-dfbe20e00834"
      },
      "source": [
        "employer_chosen = df_all_ids.groupby(by='employer')['employer'].count().sort_values(ascending=False)\n",
        "employer_chosen = set(employer_chosen[employer_chosen >= 5].index)\n",
        "employer_chosen |= set(df_all_ids.loc[~df_all_ids['is_train'], 'employer'])\n",
        "\n",
        "len(employer_chosen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUzGioNj9u90",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "7ac8bb21-c2bc-4ead-b490-6af5600193dd"
      },
      "source": [
        "df_all_ids.loc[~df_all_ids['employer'].isin(employer_chosen), 'employer'] = 'UNKNOWN'\n",
        "df_all_ids.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>specializations</th>\n",
              "      <th>is_train</th>\n",
              "      <th>area_id</th>\n",
              "      <th>compensation_from</th>\n",
              "      <th>compensation_to</th>\n",
              "      <th>creation_date</th>\n",
              "      <th>currency</th>\n",
              "      <th>employer</th>\n",
              "      <th>employment</th>\n",
              "      <th>work_experience</th>\n",
              "      <th>work_schedule</th>\n",
              "      <th>joined_work</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>vacancy_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[242, 256, 302, 324, 358, 440]</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "      <td>22000.0</td>\n",
              "      <td>24000.0</td>\n",
              "      <td>2019-01-24</td>\n",
              "      <td>RUR</td>\n",
              "      <td>0ce23382345c</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>160</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-07-26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b9aa259f8724</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[211]</td>\n",
              "      <td>True</td>\n",
              "      <td>1002</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-04-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>11ecc72a7a76</td>\n",
              "      <td>project</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>project_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[389, 412, 437]</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36000.0</td>\n",
              "      <td>2019-07-12</td>\n",
              "      <td>RUR</td>\n",
              "      <td>UNKNOWN</td>\n",
              "      <td>full</td>\n",
              "      <td>noExperience</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_noExperience_fullDay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>1002</td>\n",
              "      <td>600.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>BYR</td>\n",
              "      <td>943fd4a3770a</td>\n",
              "      <td>full</td>\n",
              "      <td>between1And3</td>\n",
              "      <td>fullDay</td>\n",
              "      <td>full_between1And3_fullDay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           specializations  ...                   joined_work\n",
              "vacancy_id                                  ...                              \n",
              "1           [242, 256, 302, 324, 358, 440]  ...     full_between1And3_fullDay\n",
              "2                                      NaN  ...     full_between1And3_fullDay\n",
              "3                                    [211]  ...  project_between1And3_fullDay\n",
              "4                          [389, 412, 437]  ...     full_noExperience_fullDay\n",
              "5                                      NaN  ...     full_between1And3_fullDay\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoCj8bru-bxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b85bdde5-3128-46d7-b90e-b2026562a9d6"
      },
      "source": [
        "features_employer = pd.get_dummies(df_all_ids['employer'], sparse=True)\n",
        "features_employer = features_employer.sparse.to_coo().tocsr()\n",
        "features_employer.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2912650, 257995)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Qb9mgU5w5Rm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_onehot_csr_matrix(s: pd.Series):\n",
        "    mapping = defaultdict(lambda: len(mapping))\n",
        "\n",
        "    data = np.ones(shape=(s.shape[0], ))\n",
        "    indices = [mapping[k] for k in s]\n",
        "    indptr = np.arange(0, len(data) + 1)\n",
        "\n",
        "    X = sp.csr_matrix((data, indices, indptr), shape=(len(indptr) - 1, len(mapping)))\n",
        "    mapping.default_factory = None\n",
        "    mapping_inv = sorted(mapping, key=lambda e: mapping[e])\n",
        "\n",
        "    return mapping, mapping_inv, X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m05rSmQaw7w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_onehot_multiple_csr_matrix(s: pd.Series):\n",
        "    mapping = defaultdict(lambda: len(mapping))\n",
        "\n",
        "    data, indices, indptr = [], [], [0, ]\n",
        "\n",
        "    for row in tqdm(s):\n",
        "        row = list(map(lambda e: mapping[e], row))\n",
        "\n",
        "        data.extend([1] * len(row))\n",
        "        indices.extend(row)\n",
        "        indptr.append(len(data))\n",
        "\n",
        "    X = sp.csr_matrix((data, indices, indptr), shape=(len(indptr) - 1, len(mapping)))\n",
        "    mapping.default_factory = None\n",
        "    mapping_inv = sorted(mapping, key=lambda e: mapping[e])\n",
        "\n",
        "    return mapping, mapping_inv, X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e2uGGdzxNM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9508aa4-046d-409f-a8e4-3bbe82bf9cb8"
      },
      "source": [
        "mapping_spec, mapping_spec_inv, y_spec = \\\n",
        "    make_onehot_multiple_csr_matrix(df_all_ids.loc[df_all_ids['is_train'], 'specializations'])\n",
        "\n",
        "y_spec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1456325/1456325 [00:02<00:00, 546319.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1456325, 620)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYm7HjJkLU9L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c37581c4-3987-4d5e-e8ad-c64513e66bd4"
      },
      "source": [
        "vacancies_parts = (f for f in os.listdir(WORKDIR) if f.startswith('vacancies-'))\n",
        "vacancies_parts = sorted(vacancies_parts)\n",
        "vacancies_parts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['vacancies-01.json.gz',\n",
              " 'vacancies-02.json.gz',\n",
              " 'vacancies-03.json.gz',\n",
              " 'vacancies-04.json.gz',\n",
              " 'vacancies-05.json.gz',\n",
              " 'vacancies-06.json.gz',\n",
              " 'vacancies-07.json.gz',\n",
              " 'vacancies-08.json.gz',\n",
              " 'vacancies-09.json.gz',\n",
              " 'vacancies-10.json.gz']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmv0omfcLbLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_vacancies_part(filename):\n",
        "    with gzip.open(filename, mode='r') as f_gz:\n",
        "        records = json.load(f_gz)\n",
        "        records = {int(k): v for k, v in records.items()}\n",
        "    return records"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJgRAIyLNh-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import lru_cache\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "\n",
        "ru_morph = MorphAnalyzer()\n",
        "\n",
        "@lru_cache(maxsize=15000)\n",
        "def morph_process(token):\n",
        "    return ru_morph.parse(token)[0].normal_form\n",
        "\n",
        "@lru_cache(maxsize=5000)\n",
        "def preprocess_skill(s):\n",
        "    parts = re.sub('\\s+', ' ', s.strip().lower()).split()\n",
        "    parts = map(morph_process, parts)\n",
        "    return '_'.join(parts)\n",
        "\n",
        "stop_words = map(morph_process, stopwords.words('russian'))\n",
        "stop_words = stopwords.words('russian') + list(stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzw4Qr2HOdrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_names_reader(vacancies_it, index):\n",
        "    for vacancy_id, vacancy_info in vacancies_it:\n",
        "        # name = re.sub('\\(.*?\\)', '', vacancy_info['name'].lower())\n",
        "        name = vacancy_info['name'].lower()\n",
        "        index.append(vacancy_id)\n",
        "        yield name\n",
        "\n",
        "def content_skills_reader(vacancies_it, index):\n",
        "    for vacancy_id, vacancy_info in vacancies_it:\n",
        "        skills = ' '.join(map(preprocess_skill, vacancy_info['key_skills']))\n",
        "        index.append(vacancy_id)\n",
        "        yield skills"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltnZRdzoNlve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def create_tfidf_vectorizer(mode, **params):\n",
        "    if mode == 'names':\n",
        "        vec = TfidfVectorizer(\n",
        "            stop_words=stop_words,\n",
        "            token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
        "            preprocessor=morph_process,\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=5,\n",
        "            **params\n",
        "        )\n",
        "    elif mode == 'skills':\n",
        "        vec = TfidfVectorizer(\n",
        "            stop_words=stop_words,\n",
        "            token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
        "            min_df=5,\n",
        "            **params\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(mode)\n",
        "\n",
        "    return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqigDlIM2fW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_tfdif_vectors(mode,\n",
        "                         content_array_file,\n",
        "                         content_terms_idfs,\n",
        "                         content_vacancies_mapping, ):\n",
        "    vacancies_it = map(lambda p: os.path.join(WORKDIR, p), tqdm(vacancies_parts))\n",
        "    vacancies_it = map(read_vacancies_part, vacancies_it)\n",
        "    vacancies_it = ((k, v) for p in vacancies_it for k, v in p.items())\n",
        "\n",
        "    index = []\n",
        "\n",
        "    if mode == 'names':\n",
        "        content = tqdm(content_names_reader(vacancies_it, index), position=0)\n",
        "    elif mode == 'skills':\n",
        "        content = tqdm(content_skills_reader(vacancies_it, index), position=0)\n",
        "    else:\n",
        "        raise ValueError(mode)\n",
        "\n",
        "    vec = create_tfidf_vectorizer(mode)\n",
        "\n",
        "    # Считаем tfidf-вектора и сохраняем их\n",
        "    features = vec.fit_transform(content)\n",
        "    save_array(features, content_array_file, sparse=True)\n",
        "\n",
        "    # Сохраняем словарик с idf\n",
        "    vocabulary_inv = sorted(vec.vocabulary_, key=lambda e: vec.vocabulary_[e])\n",
        "    with open(content_terms_idfs, mode='w', encoding='utf8') as f_data:\n",
        "        for word, idf in zip(vocabulary_inv, vec.idf_):\n",
        "            print(word, \"%.16f\" % idf, sep='\\t', file=f_data)\n",
        "\n",
        "    # Сохраняем порядок вакансий в матрице\n",
        "    with open(content_vacancies_mapping, mode='w') as f_data:\n",
        "        print(*index, sep='\\n', file=f_data)\n",
        "\n",
        "    return vec, features, index\n",
        "\n",
        "\n",
        "def load_tfidf_vectors(mode,\n",
        "                       content_array_file,\n",
        "                       content_terms_idfs,\n",
        "                       content_vacancies_mapping, ):\n",
        "    # Грузим tfidf-вектора\n",
        "    features = load_array(content_array_file, sparse=True)\n",
        "\n",
        "    # Грузим TfIdfVectorizer\n",
        "    with open(content_terms_idfs, mode='r') as f_data:\n",
        "        f_data = map(lambda s: s.rstrip().split('\\t'), f_data)\n",
        "\n",
        "        vocabulary_inv, vocabulary_idf = [], []\n",
        "        for i, (word, idf) in enumerate(f_data):\n",
        "            vocabulary_inv.append(word)\n",
        "            vocabulary_idf.append(float(idf))\n",
        "\n",
        "    vec = create_tfidf_vectorizer(mode=mode, vocabulary=vocabulary_inv)\n",
        "    vec.idf_ = np.asarray(vocabulary_idf, dtype=float)\n",
        "\n",
        "    # Грузим порядок документов\n",
        "    with open(content_vacancies_mapping, mode='r') as f_data:\n",
        "        index = list(map(int, f_data))\n",
        "\n",
        "    return vec, features, index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_bvV52z0PE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a8dcac0-76fe-4730-950d-41fcf2f4b940"
      },
      "source": [
        "content_names_array_file = os.path.join(WORKDIR, 'data/content_names_2.npz')\n",
        "content_names_terms_idfs = os.path.join(WORKDIR, 'data/content_names_2.idf')\n",
        "content_names_vacancies_mapping = os.path.join(WORKDIR, 'data/content_names_2.mapping')\n",
        "\n",
        "if not os.path.isfile(content_names_array_file):\n",
        "    index = []\n",
        "\n",
        "    vec, features_content_names, index = create_tfdif_vectors(\n",
        "        'names',\n",
        "        content_names_array_file,\n",
        "        content_names_terms_idfs,\n",
        "        content_names_vacancies_mapping,\n",
        "    )\n",
        "else:\n",
        "    vec, features_content_names, index = load_tfidf_vectors(\n",
        "        'names',\n",
        "        content_names_array_file,\n",
        "        content_names_terms_idfs,\n",
        "        content_names_vacancies_mapping,\n",
        "    )\n",
        "\n",
        "# Убеждаемся, что все правильно\n",
        "assert (np.asarray(index) == df_all_ids.index.values).all()\n",
        "assert features_content_names.shape == (df_all_ids.shape[0], len(vec.idf_))\n",
        "\n",
        "features_content_names.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2912650, 139435)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNDSNebV5Npm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00471edc-e6df-4fb9-8a74-bb5d348e2a49"
      },
      "source": [
        "content_skills_array_file = os.path.join(WORKDIR, 'data/content_skills_2.npz')\n",
        "content_skills_terms_idfs = os.path.join(WORKDIR, 'data/content_skills_2.idf')\n",
        "content_skills_vacancies_mapping = os.path.join(WORKDIR, 'data/content_skills_2.mapping')\n",
        "\n",
        "if not os.path.isfile(content_skills_array_file):\n",
        "    index = []\n",
        "\n",
        "    vec, features_content_skills, index = create_tfdif_vectors(\n",
        "        'skills',\n",
        "        content_skills_array_file,\n",
        "        content_skills_terms_idfs,\n",
        "        content_skills_vacancies_mapping,\n",
        "    )\n",
        "else:\n",
        "    vec, features_content_skills, index = load_tfidf_vectors(\n",
        "        'skills',\n",
        "        content_skills_array_file,\n",
        "        content_skills_terms_idfs,\n",
        "        content_skills_vacancies_mapping,\n",
        "    )\n",
        "\n",
        "# Убеждаемся, что все правильно\n",
        "assert (np.asarray(index) == df_all_ids.index.values).all()\n",
        "assert features_content_skills.shape == (df_all_ids.shape[0], len(vec.idf_))\n",
        "\n",
        "features_content_skills.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2912650, 19402)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiNrUaNcP1S5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class HHDataset(Dataset):\n",
        "    def __init__(self, content_names, vacancy_info, employer_info, skills_info, target,\n",
        "                 batch_size=100, shuffle=True, random_state=None):\n",
        "        self.check_shapes(\n",
        "            content_names,\n",
        "            vacancy_info,\n",
        "            employer_info,\n",
        "            skills_info,\n",
        "            target,\n",
        "        )\n",
        "\n",
        "        self.content_names = content_names\n",
        "        self.vacancy_info = vacancy_info\n",
        "        self.employer_info = employer_info\n",
        "        self.skills_info = skills_info\n",
        "        self.target = target\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "        if random_state is not None and isinstance(random_state, np.random.RandomState):\n",
        "            self.random_state = random_state\n",
        "        else:\n",
        "            self.random_state = np.random.RandomState(random_state)\n",
        "\n",
        "        # init index\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def check_shapes(self, *args):\n",
        "        args = args[:-1] if args[-1] is None else args\n",
        "\n",
        "        shapes = map(lambda e: e.shape[0], args)\n",
        "        shapes = list(shapes)\n",
        "\n",
        "        # https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical\n",
        "\n",
        "        assert shapes.count(shapes[0]) == len(shapes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(math.ceil(self.content_names.shape[0] / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        index = self.index[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        \n",
        "        batch_content_names = self.content_names[index]\n",
        "        batch_vacancy_info = self.vacancy_info[index]\n",
        "        batch_employer_info = self.employer_info[index]\n",
        "        batch_skills_info = self.skills_info[index]\n",
        "        \n",
        "        if self.target is not None:\n",
        "            batch_y = self.target[index]\n",
        "            batch_y = batch_y.toarray()\n",
        "        else:\n",
        "            # inference mode\n",
        "            batch_y = None\n",
        "\n",
        "        batch_x = (\n",
        "            batch_content_names.toarray(),\n",
        "            batch_vacancy_info.toarray(),\n",
        "            batch_employer_info.toarray(),\n",
        "            batch_skills_info.toarray(),\n",
        "        )\n",
        "\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.index = self.random_state.permutation(self.content_names.shape[0])\n",
        "        else:\n",
        "            self.index = np.arange(self.content_names.shape[0])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnFdYXQKjWmG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8ac62a5f-c7ed-41b4-ddb5-a4b031fab65b"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class HHNetwork(nn.Module):\n",
        "    def __init__(self, num_content_names, num_vacancy_info, num_employer_info, num_skills_info, num_target):\n",
        "        super().__init__()\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                in_features=num_content_names + num_vacancy_info + num_employer_info + num_skills_info,\n",
        "                out_features=num_target,\n",
        "                bias=True,\n",
        "            ),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, content_names, vacancy_info, employer_info, skills_info):\n",
        "        x = torch.cat((content_names, vacancy_info, employer_info, skills_info), dim=1)\n",
        "        x = self.network(x)\n",
        "        return x\n",
        "\n",
        "clf = HHNetwork(\n",
        "    num_content_names=features_content_names.shape[1],\n",
        "    num_vacancy_info=features_vacancy_info.shape[1],\n",
        "    num_employer_info=features_employer.shape[1],\n",
        "    num_skills_info=features_content_skills.shape[1],\n",
        "    num_target=len(mapping_spec),\n",
        ").cuda()\n",
        "\n",
        "criteria = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(clf.parameters(), lr=0.01)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "    optimizer,\n",
        "    milestones=[3, 7, ],\n",
        "    gamma=0.1,\n",
        ")\n",
        "\n",
        "clf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HHNetwork(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=416846, out_features=620, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-LFmLgLtKR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_tensor(X, use_cuda=True):\n",
        "    if not torch.is_tensor(X):\n",
        "        device = 'cuda' if use_cuda else 'cpu'\n",
        "        X = torch.tensor(X, device=device, dtype=torch.float32)\n",
        "\n",
        "    if use_cuda and not X.is_cuda:\n",
        "        X = X.cuda()\n",
        "\n",
        "    if not torch.is_floating_point(X):\n",
        "        X = X.float()\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuNOFQiXvyYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_best_ranks(ranks: np.ndarray, top: int, axis: int = 0, return_ranks: bool = False):\n",
        "    top_slice = (slice(None), ) * axis + (slice(-top, None), )\n",
        "    inv_slice = (slice(None), ) * axis + (slice(None, None, -1), )\n",
        "\n",
        "    if top < ranks.shape[axis]:\n",
        "        indices = np.argpartition(ranks, -top, axis=axis)[top_slice]\n",
        "        ranks_top = np.take_along_axis(ranks, indices, axis=axis)\n",
        "        indices = np.take_along_axis(indices, ranks_top.argsort(axis=axis)[inv_slice], axis=axis)\n",
        "    else:\n",
        "        indices = np.argsort(ranks, axis=axis)[top_slice]\n",
        "        indices = indices[inv_slice]\n",
        "\n",
        "    result = (indices, )\n",
        "\n",
        "    if return_ranks:\n",
        "        ranks = np.take_along_axis(ranks, indices, axis=axis)\n",
        "        result += (ranks, )\n",
        "\n",
        "    return result if len(result) > 1 else result[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyWEgCtTv4n-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f1score(y_true, y_pred):\n",
        "    # y_true = set(y_true)\n",
        "    # y_pred = set(y_pred)\n",
        "    \n",
        "    tp = len(y_true & y_pred)\n",
        "    precision = tp / len(y_pred)\n",
        "    recall = tp / len(y_true)\n",
        "    if precision == 0.0 and recall == 0.0:\n",
        "        score = 0.0\n",
        "    else:\n",
        "        score = 2 * precision * recall / (precision + recall)\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBh6LDgBS_a2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predict(model, seq, top=3, return_ranks=False):\n",
        "    y_pred, y_true, ranks_pred_all = [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(seq)), position=0, leave=False):\n",
        "        X_test, y_test = seq[i]\n",
        "        \n",
        "        if y_test is not None:\n",
        "            y_test = sp.csr_matrix(y_test)\n",
        "            y_true.append(y_test)\n",
        "\n",
        "        y_batch_pred = model(*map(to_tensor, X_test))\n",
        "        y_batch_pred = y_batch_pred.cpu().detach().numpy()\n",
        "\n",
        "        res = get_best_ranks(y_batch_pred, top=top, axis=1, return_ranks=return_ranks)\n",
        "        if return_ranks:\n",
        "            indices_pred, ranks_pred = res\n",
        "        else:\n",
        "            indices_pred, ranks_pred = res, None\n",
        "\n",
        "        y_pred.append(indices_pred)\n",
        "        ranks_pred_all.append(ranks_pred)\n",
        "\n",
        "    y_true = sp.vstack(y_true) if y_true else None\n",
        "    y_pred = np.vstack(y_pred)\n",
        "    \n",
        "    res = (y_true, y_pred, )\n",
        "    \n",
        "    if return_ranks:\n",
        "        ranks_pred = np.vstack(ranks_pred_all)\n",
        "        res += (ranks_pred, )\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vpZ0Ebnv6fT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate(model, seq, top=3):\n",
        "    y_true, y_pred = make_predict(model, seq, top=top, return_ranks=False)\n",
        "    \n",
        "    y_true = list(map(set, y_true.tolil().rows))\n",
        "    y_pred = list(map(set, y_pred))\n",
        "\n",
        "    assert len(y_true) == len(y_pred)\n",
        "\n",
        "    scores = tqdm(zip(y_true, y_pred), total=len(y_true), position=0, leave=False)\n",
        "    scores = [f1score(*pair) for pair in scores]\n",
        "    scores = np.asarray(scores)\n",
        "    return np.mean(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FRoThULolw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "mask = df_all_ids['is_train'].values\n",
        "\n",
        "( features_content_names_train, features_content_names_valid,\n",
        "  features_vacancy_info_train, features_vacancy_info_valid,\n",
        "  features_employer_train, features_employer_valid,\n",
        "  features_content_skills_train, features_content_skills_valid, \n",
        "  y_train, y_valid ) = train_test_split(\n",
        "      features_content_names[mask],\n",
        "      features_vacancy_info[mask],\n",
        "      features_employer[mask],\n",
        "      features_content_skills[mask],\n",
        "      y_spec,\n",
        "      test_size=0.3,\n",
        "      random_state=9872,\n",
        ")\n",
        "  \n",
        "features_content_names_test = features_content_names[~mask]\n",
        "features_vacancy_info_test = features_vacancy_info[~mask]\n",
        "features_employer_test = features_employer[~mask]\n",
        "features_content_skills_test = features_content_skills[~mask]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjfT-vX8s5kO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "b483bdf4-a901-4a73-96aa-04628330d009"
      },
      "source": [
        "%%time\n",
        "\n",
        "input_train = HHDataset(features_content_names_train, features_vacancy_info_train,\n",
        "                        features_employer_train, features_content_skills_train, y_train,\n",
        "                        batch_size=256, shuffle=True, random_state=42, )\n",
        "\n",
        "input_valid = HHDataset(features_content_names_valid, features_vacancy_info_valid,\n",
        "                        features_employer_valid, features_content_skills_valid, y_valid,\n",
        "                        batch_size=256, shuffle=False, random_state=42, )\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    clf.train()\n",
        "\n",
        "    desc = 'Epoch: {}'.format(epoch + 1)\n",
        "    pbar = tqdm(range(len(input_train)), desc=desc, position=0, leave=True)\n",
        "\n",
        "    for i in pbar:\n",
        "        X_batch, y_batch_true = input_train[i]\n",
        "        y_batch_pred = clf(*map(to_tensor, X_batch))\n",
        "        loss = criteria(y_batch_pred, to_tensor(y_batch_true))\n",
        "\n",
        "        pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    clf.eval()\n",
        "    \n",
        "    score = validate(clf, input_valid, top=3)\n",
        "\n",
        "    print('\\n', end='')\n",
        "    print('f-measure = {:.6f}'.format(score))\n",
        "\n",
        "    input_train.on_epoch_end()\n",
        "    input_valid.on_epoch_end()\n",
        "    scheduler.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1: 100%|██████████| 3983/3983 [23:06<00:00,  2.87it/s, loss=0.0112]\n",
            "Epoch: 2:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.518119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 2: 100%|██████████| 3983/3983 [23:08<00:00,  2.87it/s, loss=0.0126]\n",
            "Epoch: 3:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.527128\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 3: 100%|██████████| 3983/3983 [23:08<00:00,  2.87it/s, loss=0.00875]\n",
            "Epoch: 4:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.527840\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 4: 100%|██████████| 3983/3983 [23:08<00:00,  2.87it/s, loss=0.00738]\n",
            "Epoch: 5:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529217\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 5: 100%|██████████| 3983/3983 [23:07<00:00,  2.87it/s, loss=0.00853]\n",
            "Epoch: 6:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 6: 100%|██████████| 3983/3983 [23:07<00:00,  2.87it/s, loss=0.0109]\n",
            "Epoch: 7:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 7: 100%|██████████| 3983/3983 [23:08<00:00,  2.87it/s, loss=0.00618]\n",
            "Epoch: 8:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529274\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 8: 100%|██████████| 3983/3983 [23:07<00:00,  2.87it/s, loss=0.00683]\n",
            "Epoch: 9:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 9: 100%|██████████| 3983/3983 [23:10<00:00,  2.87it/s, loss=0.0083]\n",
            "Epoch: 10:   0%|          | 0/3983 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529323\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10: 100%|██████████| 3983/3983 [23:07<00:00,  2.87it/s, loss=0.00934]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "f-measure = 0.529286\n",
            "CPU times: user 5h 7min 2s, sys: 23min 17s, total: 5h 30min 19s\n",
            "Wall time: 5h 30min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcbbWLCH6Wxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(clf.state_dict(), os.path.join(WORKDIR, 'models/model_logreg_017_empl_skills.pt'))\n",
        "\n",
        "with open(os.path.join(WORKDIR, 'models/model_logreg_017_empl_skills_spec.mapping'), mode='w') as f_mapping:\n",
        "    print(*mapping_spec_inv, sep='\\n', file=f_mapping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79GA-G7vMHgR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d639b8e-c393-4f9b-e4de-be68ef6d373c"
      },
      "source": [
        "from hyperopt import fmin, tpe, hp, Trials\n",
        "\n",
        "space = hp.uniform('threshold', 0.01, 0.99)\n",
        "\n",
        "y_true, y_pred, ranks_valid = make_predict(clf, input_valid, top=15, return_ranks=True)\n",
        "\n",
        "def objective(threshold):\n",
        "    mask = ranks_valid > threshold\n",
        "    mask[:, 0] = True\n",
        "\n",
        "    indices_pred = np.where(mask, y_pred, -1)\n",
        "    indices_pred = indices_pred[:,:6]\n",
        "    indices_pred = map(lambda e: filter(lambda x: x >= 0, e), indices_pred)\n",
        "    indices_pred = map(set, indices_pred)\n",
        "\n",
        "    indices_true = map(set, y_true.tolil().rows)\n",
        "\n",
        "    scores = [f1score(*pair) for pair in zip(indices_true, indices_pred)]\n",
        "    scores = np.asarray(scores)\n",
        "\n",
        "    return -np.mean(scores)\n",
        "\n",
        "trials = Trials()\n",
        "res = fmin(objective, space, algo=tpe.suggest, max_evals=100, trials=trials,\n",
        "           rstate=np.random.RandomState(4325), verbose=1)\n",
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s, best loss: ?]\u001b[A"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  1%|          | 1/100 [00:05<08:22,  5.07s/it, best loss: -0.4708372194919398]\u001b[A\n",
            "  2%|▏         | 2/100 [00:09<08:12,  5.03s/it, best loss: -0.4708372194919398]\u001b[A\n",
            "  3%|▎         | 3/100 [00:15<08:21,  5.17s/it, best loss: -0.5167949196699968]\u001b[A\n",
            "  4%|▍         | 4/100 [00:21<08:26,  5.28s/it, best loss: -0.5254766103024118]\u001b[A\n",
            "  5%|▌         | 5/100 [00:26<08:21,  5.28s/it, best loss: -0.5535222304384738]\u001b[A\n",
            "  6%|▌         | 6/100 [00:31<08:10,  5.22s/it, best loss: -0.5638864744109628]\u001b[A\n",
            "  7%|▋         | 7/100 [00:36<08:02,  5.19s/it, best loss: -0.5638864744109628]\u001b[A\n",
            "  8%|▊         | 8/100 [00:41<07:52,  5.13s/it, best loss: -0.5725466949109503]\u001b[A\n",
            "  9%|▉         | 9/100 [00:46<07:45,  5.12s/it, best loss: -0.5725466949109503]\u001b[A\n",
            " 10%|█         | 10/100 [00:51<07:32,  5.02s/it, best loss: -0.5725466949109503]\u001b[A\n",
            " 11%|█         | 11/100 [00:56<07:39,  5.17s/it, best loss: -0.5725466949109503]\u001b[A\n",
            " 12%|█▏        | 12/100 [01:02<07:34,  5.17s/it, best loss: -0.5732526028644546]\u001b[A\n",
            " 13%|█▎        | 13/100 [01:07<07:27,  5.15s/it, best loss: -0.5732526028644546]\u001b[A\n",
            " 14%|█▍        | 14/100 [01:12<07:15,  5.07s/it, best loss: -0.5732526028644546]\u001b[A\n",
            " 15%|█▌        | 15/100 [01:17<07:17,  5.15s/it, best loss: -0.5732526028644546]\u001b[A\n",
            " 16%|█▌        | 16/100 [01:22<07:18,  5.22s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 17%|█▋        | 17/100 [01:27<07:01,  5.07s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 18%|█▊        | 18/100 [01:33<07:12,  5.28s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 19%|█▉        | 19/100 [01:37<06:53,  5.11s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 20%|██        | 20/100 [01:43<06:50,  5.14s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 21%|██        | 21/100 [01:48<06:40,  5.07s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 22%|██▏       | 22/100 [01:53<06:42,  5.16s/it, best loss: -0.5843799669607108]\u001b[A\n",
            " 23%|██▎       | 23/100 [01:58<06:40,  5.20s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 24%|██▍       | 24/100 [02:03<06:33,  5.18s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 25%|██▌       | 25/100 [02:09<06:34,  5.26s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 26%|██▌       | 26/100 [02:14<06:28,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 27%|██▋       | 27/100 [02:19<06:22,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 28%|██▊       | 28/100 [02:24<06:15,  5.22s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 29%|██▉       | 29/100 [02:30<06:12,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 30%|███       | 30/100 [02:35<06:14,  5.35s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 31%|███       | 31/100 [02:41<06:12,  5.39s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 32%|███▏      | 32/100 [02:46<06:09,  5.43s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 33%|███▎      | 33/100 [02:51<05:53,  5.28s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 34%|███▍      | 34/100 [02:57<05:47,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 35%|███▌      | 35/100 [03:02<05:37,  5.18s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 36%|███▌      | 36/100 [03:07<05:39,  5.30s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 37%|███▋      | 37/100 [03:12<05:34,  5.30s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 38%|███▊      | 38/100 [03:18<05:28,  5.29s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 39%|███▉      | 39/100 [03:23<05:21,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 40%|████      | 40/100 [03:28<05:18,  5.31s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 41%|████      | 41/100 [03:34<05:14,  5.33s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 42%|████▏     | 42/100 [03:39<05:11,  5.37s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 43%|████▎     | 43/100 [03:44<05:01,  5.29s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 44%|████▍     | 44/100 [03:50<04:55,  5.29s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 45%|████▌     | 45/100 [03:54<04:44,  5.16s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 46%|████▌     | 46/100 [04:00<04:42,  5.23s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 47%|████▋     | 47/100 [04:05<04:35,  5.20s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 48%|████▊     | 48/100 [04:10<04:31,  5.22s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 49%|████▉     | 49/100 [04:16<04:28,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 50%|█████     | 50/100 [04:21<04:23,  5.28s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 51%|█████     | 51/100 [04:26<04:11,  5.14s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 52%|█████▏    | 52/100 [04:31<04:11,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 53%|█████▎    | 53/100 [04:36<04:00,  5.11s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 54%|█████▍    | 54/100 [04:41<03:58,  5.19s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 55%|█████▌    | 55/100 [04:46<03:50,  5.13s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 56%|█████▌    | 56/100 [04:52<03:48,  5.19s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 57%|█████▋    | 57/100 [04:57<03:45,  5.23s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 58%|█████▊    | 58/100 [05:02<03:35,  5.12s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 59%|█████▉    | 59/100 [05:07<03:35,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 60%|██████    | 60/100 [05:13<03:33,  5.33s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 61%|██████    | 61/100 [05:18<03:25,  5.26s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 62%|██████▏   | 62/100 [05:24<03:23,  5.35s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 63%|██████▎   | 63/100 [05:29<03:13,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 64%|██████▍   | 64/100 [05:34<03:09,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 65%|██████▌   | 65/100 [05:39<03:01,  5.19s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 66%|██████▌   | 66/100 [05:44<02:59,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 67%|██████▋   | 67/100 [05:50<02:54,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 68%|██████▊   | 68/100 [05:55<02:46,  5.22s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 69%|██████▉   | 69/100 [06:00<02:41,  5.21s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 70%|███████   | 70/100 [06:05<02:38,  5.29s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 71%|███████   | 71/100 [06:11<02:32,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 72%|███████▏  | 72/100 [06:16<02:27,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 73%|███████▎  | 73/100 [06:21<02:19,  5.17s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 74%|███████▍  | 74/100 [06:26<02:16,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 75%|███████▌  | 75/100 [06:31<02:08,  5.15s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 76%|███████▌  | 76/100 [06:37<02:05,  5.23s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 77%|███████▋  | 77/100 [06:42<02:00,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 78%|███████▊  | 78/100 [06:47<01:54,  5.20s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 79%|███████▉  | 79/100 [06:52<01:50,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 80%|████████  | 80/100 [06:58<01:46,  5.32s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 81%|████████  | 81/100 [07:03<01:39,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 82%|████████▏ | 82/100 [07:08<01:34,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 83%|████████▎ | 83/100 [07:14<01:30,  5.29s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 84%|████████▍ | 84/100 [07:19<01:26,  5.41s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 85%|████████▌ | 85/100 [07:24<01:19,  5.31s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 86%|████████▌ | 86/100 [07:30<01:14,  5.34s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 87%|████████▋ | 87/100 [07:35<01:09,  5.34s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 88%|████████▊ | 88/100 [07:40<01:02,  5.25s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 89%|████████▉ | 89/100 [07:45<00:57,  5.27s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 90%|█████████ | 90/100 [07:51<00:53,  5.37s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 91%|█████████ | 91/100 [07:56<00:47,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 92%|█████████▏| 92/100 [08:01<00:42,  5.26s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 93%|█████████▎| 93/100 [08:07<00:37,  5.34s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 94%|█████████▍| 94/100 [08:12<00:32,  5.36s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 95%|█████████▌| 95/100 [08:17<00:26,  5.24s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 96%|█████████▌| 96/100 [08:23<00:21,  5.35s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 97%|█████████▋| 97/100 [08:28<00:16,  5.37s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 98%|█████████▊| 98/100 [08:33<00:10,  5.28s/it, best loss: -0.5844294965348965]\u001b[A\n",
            " 99%|█████████▉| 99/100 [08:39<00:05,  5.28s/it, best loss: -0.5844294965348965]\u001b[A\n",
            "100%|██████████| 100/100 [08:44<00:00,  5.24s/it, best loss: -0.5844294965348965]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'threshold': 0.2753375301431183}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS2b8Xh35v9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee8bee6e-52ca-458f-93af-f5a71603576a"
      },
      "source": [
        "threshold_best = res['threshold']\n",
        "threshold_best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2753375301431183"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1hHWRGMnz1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_valid_file = os.path.join(WORKDIR, 'data/logreg-employer-valid.indices.npz')\n",
        "ranks_valid_file = os.path.join(WORKDIR, 'data/logreg-employer-valid.ranks.npz')\n",
        "\n",
        "save_array(ranks_valid, ranks_valid_file, sparse=False)\n",
        "save_array(y_pred, indices_valid_file, sparse=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBswCMWeoe_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78c2f5cd-540e-46ae-d439-a75a012d3323"
      },
      "source": [
        "input_test = HHDataset(features_content_names_test, features_vacancy_info_test,\n",
        "                       features_employer_test, features_content_skills_test, None,\n",
        "                       batch_size=2048, shuffle=False, random_state=42, )\n",
        "\n",
        "indices_test, ranks_test = [], []\n",
        "\n",
        "for i in tqdm(range(len(input_test)), position=0, leave=True):\n",
        "    X_batch, _ = input_test[i]\n",
        "\n",
        "    y_batch = clf(*map(to_tensor, X_batch))\n",
        "    y_batch = y_batch.cpu().detach().numpy()\n",
        "    \n",
        "    indices_pred, ranks_pred = get_best_ranks(y_batch, top=6, axis=1, return_ranks=True)\n",
        "    \n",
        "    indices_test.append(indices_pred)\n",
        "    ranks_test.append(ranks_pred)\n",
        "\n",
        "indices_test = np.vstack(indices_test)\n",
        "ranks_test = np.vstack(ranks_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 712/712 [54:40<00:00,  4.61s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvqNz6_ioddc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indices_test_file = os.path.join(WORKDIR, 'data/logreg-employer-test.indices.npz')\n",
        "ranks_test_file = os.path.join(WORKDIR, 'data/logreg-employer-test.ranks.npz')\n",
        "\n",
        "save_array(ranks_test, ranks_test_file, sparse=False)\n",
        "save_array(indices_test, indices_test_file, sparse=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdAWwRC3ZAgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b3a87658-e032-4527-ee6e-e028335df59f"
      },
      "source": [
        "%%time\n",
        "\n",
        "def convert_specializations(s):\n",
        "    s = set(s)\n",
        "    s = map(lambda e: mapping_spec_inv[e], s)\n",
        "    s = sorted(s)\n",
        "    # s = np.asarray(s, dtype=int)\n",
        "    return s\n",
        "\n",
        "use_smart = True\n",
        "\n",
        "y_pred_all = []\n",
        "\n",
        "if use_smart:\n",
        "    mask = ranks_test > threshold_best\n",
        "    mask[:, 0] = True\n",
        "\n",
        "    indices_pred = np.where(mask, indices_test, -1)\n",
        "    indices_pred = map(lambda e: filter(lambda x: x >= 0, e), indices_pred)\n",
        "else:\n",
        "    indices_pred = indices_test[:,:3]\n",
        "\n",
        "y_pred_all = list(map(convert_specializations, indices_pred))\n",
        "\n",
        "df_submission = df_all_ids.loc[~df_all_ids['is_train'], ['specializations']]\n",
        "df_submission['specializations'] = y_pred_all\n",
        "\n",
        "submission_id = 17\n",
        "submission_file = os.path.join(WORKDIR, 'submission_{:03d}.csv.gz').format(submission_id)\n",
        "\n",
        "df_submission.to_csv(submission_file, index=True, compression='gzip')\n",
        "df_submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 21.7 s, sys: 174 ms, total: 21.8 s\n",
            "Wall time: 23.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URuReFnVPP0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2cef845d-9ab8-4fd6-a176-ee072841f70b"
      },
      "source": [
        "!zcat \"{submission_file}\" | head -n5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vacancy_id,specializations\n",
            "2,[211]\n",
            "5,\"[494, 541]\"\n",
            "7,[495]\n",
            "8,\"[70, 287]\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVvBkwq6Pikv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a3e1389e-c4df-4870-fa0d-54a1870dd1bf"
      },
      "source": [
        "!zcat \"{WORKDIR}/sample_submission.csv.gz\" | head -n5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vacancy_id,specializations\n",
            "2,\"[25, 324, 42]\"\n",
            "5,\"[491, 193, 313]\"\n",
            "7,[256]\n",
            "8,\"[287, 70, 83]\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFP4zq-wVeLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}